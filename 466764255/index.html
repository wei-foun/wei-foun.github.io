<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>airflow整理 | </title><meta name="keywords" content="airflow"><meta name="author" content="Legacy"><meta name="copyright" content="Legacy"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="组件介绍 WebServer：提供交互界面和监控，让开发者调试和监控所有 Task 的运行 Scheduler：负责解析和调度 Task 任务提交到 Execution 中运行 Worker：执行组件，负责运行 Scheduler 分配的 Task （根据部署可以选择 celery 或 k8s 的 executor） MetaData DataBase：AirFlow 的元数据存储数据库，记录所有">
<meta property="og:type" content="article">
<meta property="og:title" content="airflow整理">
<meta property="og:url" content="http://example.com/466764255/index.html">
<meta property="og:site_name">
<meta property="og:description" content="组件介绍 WebServer：提供交互界面和监控，让开发者调试和监控所有 Task 的运行 Scheduler：负责解析和调度 Task 任务提交到 Execution 中运行 Worker：执行组件，负责运行 Scheduler 分配的 Task （根据部署可以选择 celery 或 k8s 的 executor） MetaData DataBase：AirFlow 的元数据存储数据库，记录所有">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://wei-foun.github.io/img/cover47.jpg">
<meta property="article:published_time" content="2025-07-12T07:04:30.000Z">
<meta property="article:modified_time" content="2025-08-19T17:21:07.062Z">
<meta property="article:author" content="Legacy">
<meta property="article:tag" content="airflow">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://wei-foun.github.io/img/cover47.jpg"><link rel="shortcut icon" href="/img/favicon.ico"><link rel="canonical" href="http://example.com/466764255/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'airflow整理',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2025-08-20 01:21:07'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 5.3.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/avatar.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">57</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">37</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">55</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 文章</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 爱好收集</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://wei-foun.github.io/img/cover47.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/"></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 文章</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 爱好收集</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">airflow整理</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-07-12T07:04:30.000Z" title="发表于 2025-07-12 15:04:30">2025-07-12</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-08-19T17:21:07.062Z" title="更新于 2025-08-20 01:21:07">2025-08-20</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/airflow/">airflow</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="airflow整理"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h3 id="组件介绍"><a href="#组件介绍" class="headerlink" title="组件介绍"></a>组件介绍</h3><ul>
<li>WebServer：提供交互界面和监控，让开发者调试和监控所有 Task 的运行</li>
<li>Scheduler：负责解析和调度 Task 任务提交到 Execution 中运行</li>
<li>Worker：执行组件，负责运行 Scheduler 分配的 Task （根据部署可以选择 celery 或 k8s 的 executor）</li>
<li>MetaData DataBase：AirFlow 的元数据存储数据库，记录所有 DAG 程序的信息</li>
</ul>
<p><img src="http://wei-foun.github.io/img/airflow-local.jpg" alt="img"></p>
<p><img src="http://wei-foun.github.io/img/airflow-k8s.jpg" alt="img"></p>
<h4 id="相关概念"><a href="#相关概念" class="headerlink" title="相关概念"></a>相关概念</h4><ul>
<li>dag：有向无环图，airflow 中有三种任务的定义来描述一个系任务，分别是 operators，sensors，taskflow 装饰器，taskflow 本质上也是 operator，他们都基于 baseoperator，可以将 Operator 理解为一个任务单元</li>
<li>dagrun：dag 的运行实例，由解析程序解析 dag 的 starttime、endtime、schedule_interval 等，根据定时时间生成 dagrun</li>
<li>task instance：是 dagrun 中每个 task 的运行实例，每个任务都有一个状态的生命周期。task 的运行将根据 dag 中定义的依赖关系去判断执行</li>
<li>hook：提供 airflow 与外部平台或数据库交互的访问入口</li>
<li>connection：有了 hook 来访问，就需要有 connection 来设置 hook 需要的例如访问地址，端口，账号密码等等，这些都允许 admin 账号在 ui 上设置</li>
<li>job：airflow 对 job 的提及不多，且这个 job 和 dag 的 task 是不同的概念，job 是一系列调度 task 实例组成，有自己的运行状态和开始、结束时间，每个 task 通过 job_id 关联一个 job 实例。job 有 ScheduleJob、LocalTaskJob、BackfillJob 以及 DagProcessJob 等等<ul>
<li>ScheduleJob 以守护进程运行，负责解析目录，并根据调度计划生成任务实例，判断任务之间的依赖和发送到 executor</li>
<li>LocalTaskJob 负责监控和管理任务的进程，其中 TaskRunner 会创建子进程来运行任务</li>
<li>TriggererJob 也是守护进程运行，会根据触发条件来触发 dag</li>
<li>DagProcessJob 是用于处理 dag 文件解析和加载的任务</li>
</ul>
</li>
</ul>
<h4 id="工作原理"><a href="#工作原理" class="headerlink" title="工作原理"></a>工作原理</h4><ol>
<li>Scheduler 定期扫描 DAG 文件目录，检查 Metadata Database 中是否已经有 DAG Run 实例</li>
<li>Scheduler 查看 DAG 的 dependencies，将关联的任务加到 queue 中，更新 Database 中 Taskinstance 的状态为 <code>queue</code></li>
<li>Scheduler 将 queue 中的任务分配给 Executor，Executor 接收到后启动 worker 来执行 task，Worker 开始执行时，Taskinstance 的状态 <code>running</code></li>
<li>根据任务执行的结果 Taskinstance 的状态会发生变化例如 <code>failed</code>、<code>success</code> 等</li>
<li>一旦所有 queued 的 task 全部完成，Scheduler 会查看目前 DAG Run 所有 task 的结果，最后将 DAG Run 状态设置为 <code>failed</code> 或 <code>success</code></li>
</ol>
<p>​     <strong>！！注意 ！！</strong> worker 是 dag 的真正执行组件，所以 worker 必然需要 dag 目录</p>
<h3 id="角色权限"><a href="#角色权限" class="headerlink" title="角色权限"></a>角色权限</h3><p>​        airflow 的 ui 操作通过 flask appbuilder（FAB）进行实现，其中默认有 5 类角色，public，viewer，user，op，admin（权限大小按照从左至右排序）</p>
<ul>
<li><strong>public：</strong>表示的是匿名用户，没有任何权限，所以也无法通过登录进入到内部进行查看和操作</li>
<li><strong>viewer：</strong>拥有了很多基础的查看的能力，包括 dag 以及一些菜单栏中和 dag 相关的数据查看，但是没有 dag 的激活，触发执行，编辑，删除能力</li>
<li><strong>user：</strong> 基于 viewer 之上，增加 viewer 没有的 dag 相关的操作能力和 datasets 的创建</li>
<li><strong>op：</strong>在基于 user 之上，增加 airflow 的一些配置相关的操作和修改，例如，变量，连接，并发池 等等</li>
<li><strong>admin：</strong>基于 op 之上，增加安全性与审计相关的配置操作，例如，对添加用户，用户赋权，日志审计</li>
</ul>
<h4 id="自定义-role-和权限"><a href="#自定义-role-和权限" class="headerlink" title="自定义 role 和权限"></a>自定义 role 和权限</h4><p>Admin 角色管理可以在 webserver ui 上 security 下进行 user 和 role 的编辑管理操作</p>
<p>​      需要能够访问 ui，添加：can read on Website</p>
<p>​      需要能够访问 dag 菜单，和指定 dag，添加：menu access on DAGs，can read on DAG:host_demo。如果需要编辑，删除就是对应的 edit 和 delete</p>
<p>​      更多内容：<a target="_blank" rel="noopener" href="https://airflow.apache.org/docs/apache-airflow-providers-fab/stable/auth-manager/access-control.html#resource-based-permissions">https://airflow.apache.org/docs/apache-airflow-providers-fab/stable/auth-manager/access-control.html#resource-based-permissions</a></p>
<h4 id="api-认证"><a href="#api-认证" class="headerlink" title="api 认证"></a>api 认证</h4><p>​        默认 airflow 的 RESTful api，支持 basic 和 session 两种认证，basic 是基于 base64 的 <code>username:passwd</code> 之后放到请求头</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Authorization: Basic xxxxxxxx==</span><br></pre></td></tr></table></figure>
<p>​        当 user 设定了特定的 dag 权限后，无法访问的 dag 使用 api 调用会自动 forbidden</p>
<h3 id="连接管理"><a href="#连接管理" class="headerlink" title="连接管理"></a>连接管理</h3><p>​        airflow 中 admin 面板下可以设置 connections，其中可以配置各种例如，数据库，云服务，ssh 等连接配置</p>
<p>​        其中一个重要字段是 extra，它的存储类型是 text，也就是 extra 可以配置一个 json 的字符串数据，通过键值对的方式实现对连接参数的补充。另外，connection 中的 password 是不会显示的</p>
<p>​        所有的 connection 都允许进行 test，默认是不开启的，需要在配置文件中 <code>AIRFLOW__CORE__TEST_CONNECTION = enabled</code> 来设置，如果 connection 配置的简单的 RESTful api，可以开启连接测试</p>
<h4 id="connection-和-hook"><a href="#connection-和-hook" class="headerlink" title="connection 和 hook"></a>connection 和 hook</h4><p>​        连接配置完成后，使用时需要通过 hook 来执行。以 http 的 conn 为例，文件表单的数据，使用 files。当然如果需要修改请求参数，run 方法内可以根据需要设置</p>
<p>​        对于一些 api 的认证 token 或秘钥，可以配置在 extra 中，然后使用 get_connection 方法获取连接，通过 extra_dejson 属性就能拿到 extra 的 json 对象</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> airflow.providers.http.hooks.http <span class="keyword">import</span> HttpHook</span><br><span class="line"></span><br><span class="line">conn = HttpHook.get_hook(<span class="string">&quot;piper_conn&quot;</span>)</span><br><span class="line">conn.method = <span class="string">&quot;POST&quot;</span></span><br><span class="line">conn.run(files=multipart_form_data)</span><br><span class="line"></span><br><span class="line">conn.run(endpoint=<span class="string">f&#x27;xxxx/api/v1/vm&#x27;</span>, data=&#123;<span class="string">&quot;provider&quot;</span>: provider, <span class="string">&quot;region&quot;</span>: region&#125;)</span><br></pre></td></tr></table></figure>
<p>​        Connection 也可以直接在代码里定义，本质上和在 webserver 上创建 connection 没有差别</p>
<p>​        具体使用感受，对于普通的 RESTful api 可以不用这个 hook 去发起请求，requests 或其他请求模块可能更方便一些</p>
<h3 id="数据查询"><a href="#数据查询" class="headerlink" title="数据查询"></a>数据查询</h3><p>​        目前看下来有三种方法：</p>
<ul>
<li>使用 mysql 的 hook，然后通过 sql 语句查询</li>
<li>使用 airflow 的 models 可以直接用 find 方法查询</li>
<li>使用 airflow 的 session，通过 query 指定 model，用 filter 方法可以进行过滤，类似 ORM</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> airflow <span class="keyword">import</span> settings</span><br><span class="line"><span class="comment"># 也可以用下面的 create_session，这个是在 settings.session 封装的，会更好一些</span></span><br><span class="line"><span class="keyword">from</span> airflow.utils.session <span class="keyword">import</span> create_session</span><br><span class="line"></span><br><span class="line"><span class="meta">@task(<span class="params">task_id=<span class="string">&quot;get_succeed_migrate_dagrun&quot;</span>, task_display_name=<span class="string">&quot;获取已完成迁移任务的参数&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_succeed_migrate_dagrun</span>(<span class="params">**kwargs</span>):</span><br><span class="line">    <span class="keyword">with</span> create_session() <span class="keyword">as</span> session:</span><br><span class="line">    <span class="comment"># session = settings.Session()</span></span><br><span class="line">        dagruns = session.query(DagRun).<span class="built_in">filter</span>(DagRun.state==<span class="string">&#x27;success&#x27;</span>, DagRun.dag_id==<span class="string">&#x27;vm_migration_test&#x27;</span>)</span><br><span class="line">   </span><br><span class="line">        res = []</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> dagruns:</span><br><span class="line">            res.append(item.conf)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> &#123;<span class="string">&quot;succeed_migrate_vm_params&quot;</span>: res&#125;</span><br></pre></td></tr></table></figure>
<h3 id="任务流"><a href="#任务流" class="headerlink" title="任务流"></a>任务流</h3><p>​        dag 中的 task 流表现形式有两种，一种使用 <code>&gt;&gt;</code> 这种语法糖的形式，另一种是直接基于 task 返回传参的方式，前者通常会需要通过 xcom 来获取前一步的 task 的返回，后者相对简便一些，但如果多个任务都接收一个任务的返回，会增加很多流的依赖</p>
<p>​        还有一种方式是通过 chain 或 chain_liner 函数，将 ti 实例按照顺序传入，airflow 会自动将任务串联起来</p>
<p>​        dag 的声明，也有两种方式，一种是使用 model 的 DAG，通过 with 语法来声明，另一种使用 decorators 的 dag 装饰器来声明 dag 函数，同时使用 task 装饰器来声明每个 task 函数</p>
<p>​        <em>补充：</em></p>
<p>​        airlfow 中所有的 task 函数中，都可以从 <code>**kwargs</code> （有些例子会写成 <code>**context</code>）中获取 dagrun 实例的参数，也就是定义 dag 的 params 属性触发时填入的对应参数</p>
<p>​        如果 dag 的参数需要在其中多个 task 使用，除了最基本的使用 task return 的 xcom，也可以在一开始将初始参数全部整理完成，覆盖到 <code>kwargs[&quot;params&quot;]</code> 或 <code>kwargs[&quot;dag_run&quot;].conf</code>，这两个某种程度上来说是相似的，dag_run 的 conf 可以来自 UI 或 api 触发时提交的数据</p>
<p>​        但是 <strong>由于 kwargs 会携带整个 dagrun 上下文，所以在任务运行性能上会有轻微的损失</strong></p>
<h3 id="包管理"><a href="#包管理" class="headerlink" title="包管理"></a>包管理</h3><p>​        airflow.cfg 配置文件中，<code>_folder =</code> 这几个配置项例如 dags_folder，plugins_folder 都会被加载到 airflow python 包搜索路径中</p>
<h3 id="任务依赖关系"><a href="#任务依赖关系" class="headerlink" title="任务依赖关系"></a>任务依赖关系</h3><p>​        通常下使用基础的 taskflow 传递和分支有时不一定能满足较为复杂的 dag 流程，所以会使用到 af 中提供的其他模块支持：</p>
<p>​        关于 trigger，sensor，dataset，api 方式的使用示例描述：<a target="_blank" rel="noopener" href="https://medium.com/datamindedbe/cross-dag-dependencies-in-apache-airflow-a-comprehensive-guide-88cbc0bc68d0">https://medium.com/datamindedbe/cross-dag-dependencies-in-apache-airflow-a-comprehensive-guide-88cbc0bc68d0</a></p>
<p>​        trigger 触发器：可以实现在 dag 中触发其他 dag，来实现跨 dag 的触发以及延迟任务的触发</p>
<p>​        sensor 传感器：可以实现基于时间线的延迟任务来等待某个任务发生，和 trigger 的不同感觉是 sensor 属于被动</p>
<p>​        datasets 数据集：除了时间调度 dag 外，也支持根据数据集更新来触发 dag 运行</p>
<h3 id="dag-管理"><a href="#dag-管理" class="headerlink" title="dag 管理"></a>dag 管理</h3><p>​        dag 文件管理，官方文档中给了几个示例：</p>
<p>​        <a target="_blank" rel="noopener" href="https://airflow.apache.org/docs/helm-chart/stable/manage-dags-files.html#">https://airflow.apache.org/docs/helm-chart/stable/manage-dags-files.html#</a></p>
<p>​        对于 docker 安装，官方的 docker-compose 文件中是在 env 中设置了目录挂载，dag 目录被挂在 webserver，triggerer，scheduler，worker 四个容器上。官方建议分布式结构下处于安全考虑 webserver 不应该可以访问 dag 文件</p>
<p>​        但是目录挂载方式，会直接覆盖掉设置的容器内对应的 /opt/airflow/dags 目录，导致构建的镜像中已存在的 dag 被覆盖掉，可以用数据卷挂载的方式，这样镜像里的 dag 将会写到宿主机上</p>
<p>​        对于 k8s 安装，则可以使用网络存储或 git-sync 来采取不同的方案</p>
<h4 id="dag-文件解析"><a href="#dag-文件解析" class="headerlink" title="dag 文件解析"></a>dag 文件解析</h4><p>​        参考文档：<a target="_blank" rel="noopener" href="https://blog.terrace.ink/article/77d23126-f6e1-4e48-9c75-41630dc139a6#7cf79b5df32f4ae8b0cbdedda2cc9e94">https://blog.terrace.ink/article/77d23126-f6e1-4e48-9c75-41630dc139a6#7cf79b5df32f4ae8b0cbdedda2cc9e94</a></p>
<p>​        默认 airflow 对 dags folder 目录每 300 秒 <code>dag_dir_list_interval</code> 进行新文件的检查，同时会启动两个解析进程每 30 秒会对 dag 文件进行解析来更新，每 60 秒会对源文件不存在的机器标记 inactive 取消显示</p>
<p>​        如果在 dags folder 添加或删除 dag 的 py 文件，除非正好进入新的轮询期，那么这些文件将需要等到 5 分钟才会被更新。删除 dag py 文件后，解析器会检查到文件不存在跳过解析</p>
<p>​        另外，需要注意，避免在 dag 源文件中引入大体量的包，或是一些复杂代码的顶层函数，因为 dag 解析程序会执行每一个 dag 文件，因此可能会导致解析时间变长，这在官方文档的最佳实践中有明确提到</p>
<h3 id="k8s-executor"><a href="#k8s-executor" class="headerlink" title="k8s executor"></a>k8s executor</h3><p>​        k8s 部署环境中，由于每个 task 将会以 pod 的形式被调度执行，因此 k8s 部署环境下，worker pod 需要使用 pod 的模版文件 pod_template_file，其中明确需要的两个字段是 image 和 name</p>
<p>​        有关模版文件的示例可以见：<a target="_blank" rel="noopener" href="https://airflow.apache.org/docs/apache-airflow-providers-cncf-kubernetes/stable/kubernetes_executor.html#example-pod-templates">https://airflow.apache.org/docs/apache-airflow-providers-cncf-kubernetes/stable/kubernetes_executor.html#example-pod-templates</a></p>
<p>​        除了可以定制自定义的 pod 模版文件外，也可以直接配置 airflow 上设置 <code>AIRFLOW__KUBERNETES__WORKER_CONTAINER_REPOSITORY</code> 和 <code>AIRFLOW__KUBERNETES__WORKER_CONTAINER_TAG</code>，这两个配置也是给 worker pod 设置镜像仓库和版本标签</p>
<p>​        补充：使用 k8s executor 执行 task 相对而言可能会增加 task 整体时间，因为 pod 的初始化可能会增加一小部分时间</p>
<h3 id="变量安全"><a href="#变量安全" class="headerlink" title="变量安全"></a>变量安全</h3><p>​        admin 角色可以对 variable 进行管理，ui 默认会对敏感的 variable 名字进行 value 隐藏，包括 connection 中的 password，目前看 variable 的 key 名称中包含 secret、private、token 字符的 value 都会进行 * 符号替换</p>
<p>​        除此之外，还可以通过 <code>sensitive_var_conn_names</code> 配置项来自定义要隐藏的 key 列表</p>
<p>​        core 配置中设置 fernet_key，目的是对 variable 数据保存做加密</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; from cryptography.fernet import Fernet</span><br><span class="line">&gt;&gt;&gt; fernet_key = Fernet.generate_key()</span><br><span class="line">&gt;&gt;&gt; print(fernet_key.decode())</span><br></pre></td></tr></table></figure>
<h3 id="Task-分支"><a href="#Task-分支" class="headerlink" title="Task 分支"></a>Task 分支</h3><p>​        airflow 有两个基于 PythonOperator 的 Operator 来支持逻辑分支功能</p>
<ul>
<li>ShortCircuitOperator：用来实现流程执行判断<ul>
<li>Task 基于 ShortCircuitOperator，如果本 Task 返回为 False 的话，其下游 Task 将被 skip；如果返回为 True 的话，其下游 Task 将会被正常执行。适合用在下游都是单线任务流的场景，注意 task_group 中使用会因为一个跳过导致整个任务组被跳过</li>
</ul>
</li>
<li>BranchPythonOperator：用来实现 Case 分支<ul>
<li>Task 基于 BranchPythonOperator，airflow 会根据本 task 的返回值（返回值是某个下游 task 的 id）来确定哪个下游 Task 将被执行，而同级下游 Task 将被 skip</li>
</ul>
</li>
</ul>
<h3 id="动态任务"><a href="#动态任务" class="headerlink" title="动态任务"></a>动态任务</h3><p>​        Dag 可以根据参数数组动态创建 task 执行，airlfow 中 task 和 task_group 都允许使用 expand 来构建动态 task</p>
<p>​        在 airflow 的 dag 中也可以有多条 chain，在触发 dagrun 后，这些 chain 会并发执行，expand 动态构建的 task 会在 map 里同样也会并发执行</p>
<p>​        在 task_group 后的任务如果要得到 group 中最后一个任务的返回，需要在 task_group 里 return 最后的 task</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@task_group</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">task_map</span>(<span class="params">cicode</span>):</span><br><span class="line"></span><br><span class="line"><span class="meta">    @task</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">t1</span>(<span class="params">cicode</span>):</span><br><span class="line">        <span class="built_in">print</span>(cicode)</span><br><span class="line">        <span class="keyword">if</span> cicode == <span class="string">&quot;123&quot;</span>:</span><br><span class="line">            <span class="keyword">raise</span> AirflowSkipException()</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @task</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">t2</span>(<span class="params">cicode</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;t2&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(cicode)</span><br><span class="line">        <span class="keyword">return</span> cicode</span><br><span class="line"></span><br><span class="line"><span class="meta">    @task</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">t3</span>(<span class="params">cicode</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;t3&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(cicode)</span><br><span class="line">        <span class="keyword">return</span> <span class="string">f&quot;t3 - <span class="subst">&#123;cicode&#125;</span>&quot;</span></span><br><span class="line"></span><br><span class="line">    task1 = t1(cicode)</span><br><span class="line">    task2 = t2(cicode)</span><br><span class="line">    task3 = t3(cicode)</span><br><span class="line"></span><br><span class="line">    chain(task1, task2, task3)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> task3</span><br><span class="line">    </span><br><span class="line"><span class="meta">@task(<span class="params">trigger_rule=<span class="string">&quot;none_failed&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">collect_result</span>(<span class="params">data</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;-&quot;</span>*<span class="number">80</span>)</span><br><span class="line">    <span class="built_in">print</span>(data)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> data:</span><br><span class="line">        <span class="built_in">print</span>(i)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;-&quot;</span>*<span class="number">80</span>) </span><br><span class="line">    </span><br><span class="line">--------------------------------------------------------------------------------</span><br><span class="line">LazySelectSequence([<span class="number">2</span> items])</span><br><span class="line">t3 - <span class="number">234</span></span><br><span class="line">t3 - <span class="number">345</span></span><br><span class="line">--------------------------------------------------------------------------------</span><br><span class="line"></span><br><span class="line"><span class="comment"># 还会见到另外一种调用方式 check_vm_data.partial(a=10).expand(region=regions)</span></span><br><span class="line">check_vm_data(region=regions[<span class="number">0</span>], a=<span class="number">10</span>)</span><br><span class="line">check_vm_data(region=regions[<span class="number">1</span>], a=<span class="number">10</span>)</span><br><span class="line">check_vm_data(region=regions[<span class="number">2</span>], a=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># expand 也可以处理多个数组参数, 例如：</span></span><br><span class="line">added_values = add.expand(x=[<span class="number">2</span>, <span class="number">4</span>, <span class="number">8</span>], y=[<span class="number">5</span>, <span class="number">10</span>])</span><br><span class="line"><span class="comment"># add(x=2, y=5)</span></span><br><span class="line"><span class="comment"># add(x=2, y=10)</span></span><br><span class="line"><span class="comment"># add(x=4, y=5)</span></span><br><span class="line"><span class="comment"># add(x=4, y=10)</span></span><br><span class="line"><span class="comment"># add(x=8, y=5)</span></span><br><span class="line"><span class="comment"># add(x=8, y=10)</span></span><br></pre></td></tr></table></figure>
<h3 id="Trigger-Rules"><a href="#Trigger-Rules" class="headerlink" title="Trigger Rules"></a>Trigger Rules</h3><p>​        默认 task 的触发规则是 all-success，也就是当前任务的所有上游任务的状态必须是完成时，才会运行自己</p>
<p>​        但是在并发执行任务中，例如 expand 根据参数动态构建的一组任务，其中某个任务执行异常失败时，这个组最后的状态也会是失败的，从而导致下游任务将无法执行</p>
<p>​        所以可以通过修改 task 的 trigger rule 来改变任务执行前对上游检查判断的状态</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">all_success (default): All upstream tasks have succeeded</span><br><span class="line"></span><br><span class="line">all_failed: All upstream tasks are in a failed or upstream_failed state</span><br><span class="line"></span><br><span class="line">all_done: All upstream tasks are done with their execution</span><br><span class="line"></span><br><span class="line">all_skipped: All upstream tasks are in a skipped state</span><br><span class="line"></span><br><span class="line">one_failed: At least one upstream task has failed (does not wait for all upstream tasks to be done)</span><br><span class="line"></span><br><span class="line">one_success: At least one upstream task has succeeded (does not wait for all upstream tasks to be done)</span><br><span class="line"></span><br><span class="line">one_done: At least one upstream task succeeded or failed</span><br><span class="line"></span><br><span class="line">none_failed: All upstream tasks have not failed or upstream_failed - that is, all upstream tasks have succeeded or been skipped</span><br><span class="line"></span><br><span class="line">none_failed_min_one_success: All upstream tasks have not failed or upstream_failed, and at least one upstream task has succeeded.</span><br><span class="line"></span><br><span class="line">none_skipped: No upstream task is in a skipped state - that is, all upstream tasks are in a success, failed, or upstream_failed state</span><br><span class="line"></span><br><span class="line">always: No dependencies at all, run this task at any time</span><br></pre></td></tr></table></figure>
<h3 id="Setup-and-teardown"><a href="#Setup-and-teardown" class="headerlink" title="Setup and teardown"></a>Setup and teardown</h3><p>​        简单来看这两个装饰器和普通线性 dag 的 task 装饰器执行逻辑不同，在 setup 和 teardown 中的任务如果出现失败，不会影响最后 teardown 任务执行</p>
<p>​        因此这两个装饰器的作用看起来有点像是 try except 和 finally，所以可以用来对任务使用到的资源做清理，释放连接等</p>
<p> 其余补充：</p>
<ul>
<li>teardown 任务当作为 dag 中最后一个任务，其状态会被 airlfow 忽略，也就是说当 <strong>teardown 任务执行失败，且没有依赖的下游任务，dagrun 的状态也会是 success，前提是 setup 任务需要至少有一个是完成的</strong></li>
<li>在 task_group 中，teardown 任务如果执行失败，这个 task_group 的状态也会被设置为 failed。如果 teardown 任务是 task_group 中最后一个，那 task_group 的下游普通 task 任务默认的上游是 teardown 的上游任务，如果 teardown 失败了，同样不会影响到这个普通 task 的执行</li>
<li>在 <strong>setup 和 teardown 中的任务被 rerun 的话，这两个 setup 和 teardown 任务同样会被重新执行</strong>。如果 setup 和 teardown 中有并行的任务链，其中一条任务链上的 ti rerun 不会让并行的其他任务链上的 ti 也重新执行</li>
</ul>
<h3 id="Sensor"><a href="#Sensor" class="headerlink" title="Sensor"></a>Sensor</h3><p>​        部分任务可能并不需要立即完成后就释放资源，可以使用 timedeltasensorasync 这个触发器来做延时执行，这些延时任务的状态会被设置为 defer，但是这些任务依然会占用 pool 中的 slots</p>
<p>​        所以应该将这些需要的延时执行任务，设定到专门的 pool 中，避免在突然大量任务执行时，这些 defer 任务占用 slots 导致其他可能优先级较高的任务阻塞一直在排队等待执行</p>
<h3 id="Xcom"><a href="#Xcom" class="headerlink" title="Xcom"></a>Xcom</h3><p>​    Task 的 return 默认会写入到 xcom，这个 xcom 可以作为参数传递给下一个 task，或者通过 <code>context[&quot;ti&quot;].xcom_pull(task_ids=&quot;&quot;)</code> 去获取指定任务返回的 xcom</p>
<p>​    如果是在 expand 的动态 task 中要使用 xcom_pull 获取上游任务的返回，还需要加上 map_indexes 参数。注意这些参数都是复数的，因此可以在一次 xcom_pull 中获取多个任务结果</p>
<p>​    <strong>注意，这个 xcom 是明文的，所以作为参数传递时，task template 的 opargs 也是明文</strong></p>
<h3 id="Ti-的状态"><a href="#Ti-的状态" class="headerlink" title="Ti 的状态"></a>Ti 的状态</h3><p>​    none：任务尚未排队等待执行（尚未满足其依赖性）</p>
<p>​    scheduled：调度程序已确定满足任务的依赖关系并且应该运行</p>
<p>​    queued：任务已分配给执行者并正在等待工作人员</p>
<p>​    running：任务正在 worker 上运行（或在 local/synchronous executor）</p>
<p>​    success：任务完成运行没有错误</p>
<p>​    shutdown：任务运行时被外部请求关闭</p>
<p>​    restarting：任务在运行时被外部请求重启</p>
<p>​    failed：任务在执行过程中出错，未能运行</p>
<p>​    skipped：由于分支、LatestOnly 或类似原因，任务被跳过</p>
<p>​    upstream_failed：上游任务失败，触发规则说我们需要它</p>
<p>​    up_for_retry：任务失败，但还有重试次数，将重新安排</p>
<p>​    up_for_reschedule：任务是一个处于重新调度模式的传感器</p>
<p>​    deferred：任务已被推迟到触发器</p>
<p>​    removed：任务自运行开始后已从 DAG 中消失</p>
<h3 id="Dag-demo"><a href="#Dag-demo" class="headerlink" title="Dag demo"></a>Dag demo</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> airflow.decorators <span class="keyword">import</span> dag, task, task_group</span><br><span class="line"><span class="keyword">from</span> airflow.models.baseoperator <span class="keyword">import</span> chain</span><br><span class="line"><span class="keyword">from</span> airflow.models.param <span class="keyword">import</span> Param</span><br><span class="line"><span class="keyword">from</span> airflow.operators.python <span class="keyword">import</span> get_current_context</span><br><span class="line"><span class="keyword">from</span> airflow.exceptions <span class="keyword">import</span> AirflowSkipException</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">logger = logging.getLogger(<span class="string">&quot;airflow.task&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@dag(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="meta">    <span class="comment"># dag_id=&quot;&quot;, # 默认是装饰的函数名称作为 dag id</span></span></span></span><br><span class="line"><span class="params"><span class="meta">    <span class="comment"># schedule_interval=None,    # 支持 cron 表达式，可以用 timedelta(days=1) 设置定时间隔</span></span></span></span><br><span class="line"><span class="params"><span class="meta">    schedule=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="meta">    <span class="comment"># &quot;hourly&quot;</span></span></span></span><br><span class="line"><span class="params"><span class="meta">    <span class="comment"># &quot;00 10 * * *&quot;   # 默认是 utc 时间，也就是按照当前时区，实际执行时间 18:00</span></span></span></span><br><span class="line"><span class="params"><span class="meta">    <span class="comment"># CronDataIntervalTimetable(&quot;0 0 * * *&quot;, timezone=&quot;Asia/Shanghai&quot;)   # 可以自定义时区</span></span></span></span><br><span class="line"><span class="params"><span class="meta">    description=<span class="string">&quot;dev dag template&quot;</span>,</span></span></span><br><span class="line"><span class="params"><span class="meta">    tags=[<span class="string">&quot;demo&quot;</span>, <span class="string">&quot;template&quot;</span>],</span></span></span><br><span class="line"><span class="params"><span class="meta">    params=&#123;</span></span></span><br><span class="line"><span class="params"><span class="meta">        <span class="string">&quot;cicodes&quot;</span>: Param(<span class="params"></span></span></span></span><br><span class="line"><span class="params"><span class="params"><span class="meta">            <span class="built_in">type</span>=<span class="string">&quot;array&quot;</span>,</span></span></span></span><br><span class="line"><span class="params"><span class="params"><span class="meta">            description=<span class="string">&quot;cicode of list&quot;</span>,</span></span></span></span><br><span class="line"><span class="params"><span class="params"><span class="meta">        </span>),</span></span></span><br><span class="line"><span class="params"><span class="meta">        <span class="string">&quot;operator&quot;</span>: Param(<span class="params"></span></span></span></span><br><span class="line"><span class="params"><span class="params"><span class="meta">            default=<span class="string">&quot;fw&quot;</span>,</span></span></span></span><br><span class="line"><span class="params"><span class="params"><span class="meta">            <span class="built_in">type</span>=<span class="string">&quot;string&quot;</span></span></span></span></span><br><span class="line"><span class="params"><span class="params"><span class="meta">        </span>)</span></span></span><br><span class="line"><span class="params"><span class="meta">    &#125;</span></span></span><br><span class="line"><span class="params"><span class="meta"></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">dag_template</span>():</span><br><span class="line"></span><br><span class="line"><span class="meta">    @task</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">task1</span>():</span><br><span class="line">        <span class="keyword">return</span> [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]</span><br><span class="line"></span><br><span class="line"><span class="meta">    @task</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">task2</span>(<span class="params">num</span>):</span><br><span class="line">        logger.info(<span class="string">f&quot;current task get num: <span class="subst">&#123;num&#125;</span>&quot;</span>)</span><br><span class="line">        name = <span class="string">f&quot;task2_<span class="subst">&#123;num&#125;</span>&quot;</span></span><br><span class="line">        <span class="keyword">if</span> name == <span class="string">&quot;task2_2&quot;</span>:</span><br><span class="line">            logger.error(<span class="string">f&quot;oops! <span class="subst">&#123;name&#125;</span> task have error&quot;</span>)</span><br><span class="line">            <span class="keyword">raise</span> AirflowSkipException(<span class="string">f&quot;<span class="subst">&#123;name&#125;</span> task will skipped&quot;</span>)</span><br><span class="line">            <span class="comment"># map 中的某个任务发生错误时设置 skip，map 任务最后状态将是 success，避免因为一个异常导致整个 map 的任务都无法继续执行下游</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> name</span><br><span class="line"></span><br><span class="line"><span class="meta">    @task.branch(<span class="params">trigger_rule=<span class="string">&quot;none_failed&quot;</span></span>)  </span><span class="comment"># 上游任务没有错误时触发，如果上游有 skip 状态任务也依然可以执行</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">branch</span>(<span class="params">**context</span>):</span><br><span class="line">        params = context[<span class="string">&quot;params&quot;</span>]</span><br><span class="line">        <span class="keyword">if</span> params[<span class="string">&quot;operator&quot;</span>] != <span class="string">&quot;fw&quot;</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="string">&quot;task4&quot;</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="string">&quot;task3&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @task</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">task3</span>():</span><br><span class="line">        ctx = get_current_context()</span><br><span class="line">        data = ctx[<span class="string">&quot;ti&quot;</span>].xcom_pull(task_ids=[<span class="string">&quot;task2&quot;</span>])</span><br><span class="line">        logger.info(<span class="string">f&quot;task have data: <span class="subst">&#123;<span class="built_in">list</span>(data)&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">    @task</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">task4</span>():</span><br><span class="line">        ctx = get_current_context()</span><br><span class="line">        data = ctx[<span class="string">&quot;ti&quot;</span>].xcom_pull(task_ids=[<span class="string">&quot;task2&quot;</span>])</span><br><span class="line">        logger.info(<span class="string">f&quot;task have data: <span class="subst">&#123;data&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">    @task_group</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">task5</span>():    <span class="comment"># task_group 接收的参数是 xcom 对象，因此不能使用 context</span></span><br><span class="line"></span><br><span class="line"><span class="meta">        @task(<span class="params">trigger_rule=<span class="string">&quot;none_failed&quot;</span></span>)</span></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">task5_1</span>():</span><br><span class="line">            logger.info(<span class="string">&quot;task5_1&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">        @task</span></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">task5_2</span>():</span><br><span class="line">            logger.info(<span class="string">&quot;task5_2&quot;</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">        chain(task5_1(), task5_2())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">    @task</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">task6</span>():</span><br><span class="line">        ctx = get_current_context()</span><br><span class="line">        data = ctx[<span class="string">&quot;ti&quot;</span>].xcom_pull(task_ids=[<span class="string">&quot;task2&quot;</span>, <span class="string">&quot;task5.task5_2&quot;</span>])</span><br><span class="line">        <span class="built_in">print</span>(data)  <span class="comment">#  LazySelectSequence([3 items])</span></span><br><span class="line">        <span class="keyword">if</span> data[<span class="number">1</span>]:</span><br><span class="line">            logger.info(<span class="string">f&quot;data is <span class="subst">&#123;<span class="built_in">list</span>(data)&#125;</span>&quot;</span>)   </span><br><span class="line">            <span class="comment"># data is [&#x27;task2_1&#x27;, &#x27;task2_3&#x27;, True]</span></span><br><span class="line">            <span class="keyword">return</span> <span class="string">&quot;done&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    t1 = task1()</span><br><span class="line">    t2 = task2.expand(num=t1)</span><br><span class="line">    t2 &gt;&gt; branch() &gt;&gt; (task3(), task4()) &gt;&gt; task5() &gt;&gt; task6()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">dag_template()</span><br></pre></td></tr></table></figure>
<h3 id="Scheduler-工作流源码分析-——-纯文字版"><a href="#Scheduler-工作流源码分析-——-纯文字版" class="headerlink" title="Scheduler 工作流源码分析 —— 纯文字版"></a>Scheduler 工作流源码分析 —— 纯文字版</h3><p>​        调度器的主要内部逻辑就是一个 loop 的循环，通过 <code>airflow scheduler</code> 命令会启动实例化一个 SchedulerJobRunner（SchedulerJobRunner 继承了 BaseJobRuner 和 LoggingMixin），此时会创建一个 job  记录，然后通过 run_job 函数内 execute_job 运行这个对象的 _execute 方法，这个执行只要正常完成，或是正确退出，就会将 job 状态设置为 success，否则就为 failed</p>
<p>​        _execute 方法会判断是否开启独立 dag-processor 的配置，默认是 False，然后实例化 DagFileProcessorAgent，然后会 start 启动一个子进程 DagFileProcessorManager 负责解析 dags 目录的文件，在此之前还会调用 executor 的 start 方法来初始化使用的 executor</p>
<p>​        在 DagFileProcessorManager  中会有一个 DagFileProcessor 子进程单独负责解析，默认配置下会按照 300 秒来对 dags-folder 的目录做一次检查来判断是否有新的 dag，同时每 30 秒会对每个文件进行处理。airflow 支持将 DagFileProcessor 进行独立部署，配置文件中将 standalone_dag_processor 设为 True 接口单独运行解析进程</p>
<p>​        然后在 _execute 会运行整个调度的核心方法 _run_scheduler_loop，这里会根据调度计划，来执行需要运行的 dag。对于定时任务，解析进程会自动创建对应的 dagrun 和 ti 写入数据库，而手动触发或 API 调用则会直接创建对应数据</p>
<p>​        _run_scheduler_loop 会有一个 timers 的时间调度器，来按照配置周期检查孤儿任务，触发超时，pool 指标，僵尸任务等等</p>
<p>​        然后就是主体循环，_do_scheduling 方法是决定调度的任务，首先会根据设计调度时间，来创建出定时任务的 dagrun，在 _start_queued_dagruns 方法将数据库中 dagrun 状态更新为 running，通过 _schedule_all_dag_runs 方法将更新 tis 的状态为 scheduled，如果 ti 是 emptyOperator 则会将状态改为 success。一开始这些在数据库中的 ti 的 state 是空值，然后会遍历返回 ti 及其 callback，_send_dag_callbacks_to_processor 会检查 cache 中的 dagrun 是否超过 SLA 设置</p>
<p>​        再往下走进入到 _critical_section_enqueue_task_instances 方法，会查找 scheduled 的 ti 并将其转为 queued 状态，然后将 ti 发送给 executor。这个方法内有两个方法，_executable_task_instances_to_queued 和 _enqueue_task_instances_with_queued_state，前者会根据一些条件查询 scheduled 的 ti，后者是这些等待执行的 ti 的相关信息写入到 executor 的 queue_task 字典中</p>
<p>​        <strong>_executable_task_instances_to_queued 里主要是会通过</strong> <strong><code>select .... For update</code></strong> <strong>来对查询结果加上锁，目的是实现多个 scheduler 运行时保证 ti 运行一致性</strong>，然后还有一些就是配置上一些参数的检查</p>
<p>​        _enqueue_task_instances_with_queued_state 方法里面遍历前面得到准备执行的 ti，将这些 ti 和其 command 以及执行队列 queue ，还有优先级通过 job 的 executor 的 queu_command 方法将这些数据写到 queue_task 中</p>
<p>​        以上是 _do_scheduling 主要内容，接着回到 _run_scheduler_loop 方法里，执行 self.job.executor.heartbeat 方法，heartbeat 方法里 trigger_tasks 会根据当前 pool 里可用 slots 数量从之前的 queue_task 里把数据放入到 task_tuples 里，在将这个元组作为参数给 _process_tasks 方法。这里根据所使用的 executor 不同，会有一些不太一样的地方。以使用 celeryexecutor 为例，_process_tasks 方法内会通过_send_tasks_to_celery 将任务异步发送给到 celery broker，然后就是 celery worker 通过监听到任务后去执行 task 的 command</p>
<p>​        当 worker 执行完成任务后，会通过事件告知 scheduler 关于 ti 的状态和信息，scheduler 的 _process_executor_events 会从 event-buffer 得到 worker 发送的信息在日志上显示。ti 离开 broker 进入 worker 后，ti 的状态从 queued 变为 running</p>
<pre><code>DR 和 TI 执行状态变化大致如下：</code></pre><p><img src="http://wei-foun.github.io/img/airflow-dr-ti-status.jpg" alt="img"></p>
<p> Dagrun 的整个状态周期：</p>
<p><img src="http://wei-foun.github.io/img/dagrun-status.jpg" alt="img"></p>
<h3 id="Celeryexecutor-工作流程"><a href="#Celeryexecutor-工作流程" class="headerlink" title="Celeryexecutor 工作流程"></a>Celeryexecutor 工作流程</h3><p><img src="http://wei-foun.github.io/img/celeryexecutor.jpg" alt="img"></p>
<p> [1] SchedulerProcess 处理任务，当它发现需要完成的任务时，将其发送到 QueueBroker</p>
<p> [2] SchedulerProcess 也会周期性的查询 ResultBackend 以获取任务的状态</p>
<p> [3] QueueBroker 当它意识到有新任务产生时，会将有关它的信息发送到 WorkerProcess </p>
<p> [4] WorkerProcess 将单个任务分配给一个 WorkerChildProcess</p>
<p> [5] WorkerChildProcess 执行适当的任务处理功能 - 关键方法：execute_command()。并创建个新的进程 - LocalTaskJobProcess</p>
<p> [6] LocalTaskJobProcess 逻辑由 LocalTaskJob 类描述。它使用 TaskRunner 启动的新进程</p>
<p> [7] RowTaskProcess 执行用户实际的代码，这一步是最底层真正执行 task 的操作</p>
<p> [8][9] Process RawTaskProcess 和 LocalTaskJobProcess 在完成task后停止</p>
<p> [10] WorkerChildProcess 通知主进程 - WorkerProcess 任务结束以及后续任务的可用性</p>
<p> [11] WorkerProcess 将状态信息保存在 ResultBackend 中</p>
<p> [12] 当 SchedulerProcess 再次询问 ResultBackend 状态时，将会获取到任务状态的信息</p>
<p>​        <strong>手动触发和 api 触发 dag，会创建 dagrun 和关联的 ti 保存到数据库，且 dagrun 的状态是 queued，ti 则是无状态，此时这些任务并不会发送给 celery 的 broker，而是等待 scheduler 的 loop 中 executor.heartbeat() 方法将 queued 的 ti 发送到 celeryexecutor，然后其 _process_tasks 方法来进行处理</strong></p>
<h3 id="参考引线"><a href="#参考引线" class="headerlink" title="参考引线"></a>参考引线</h3><ul>
<li><a target="_blank" rel="noopener" href="https://airflow.apache.org/docs/apache-airflow/2.9.2/start.html#">https://airflow.apache.org/docs/apache-airflow/2.9.2/start.html#</a> - 官方文档</li>
<li><a target="_blank" rel="noopener" href="https://www.astronomer.io/docs/learn/intro-to-airflow">https://www.astronomer.io/docs/learn/intro-to-airflow</a> - astronomer airflow 文档</li>
<li><a target="_blank" rel="noopener" href="https://workflow-engine-book.shuwoom.com/">https://workflow-engine-book.shuwoom.com/</a> - <strong>流程引擎原理与实践</strong></li>
<li><a target="_blank" rel="noopener" href="https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=103092651">https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=103092651</a> - airflow confluence</li>
<li><a target="_blank" rel="noopener" href="https://airflow.apache.org/docs/apache-airflow-providers-celery/stable/celery_executor.html">https://airflow.apache.org/docs/apache-airflow-providers-celery/stable/celery_executor.html</a> - celery-executor</li>
<li><a target="_blank" rel="noopener" href="https://github.com/jghoman/awesome-apache-airflow?tab=readme-ov-file#best-practices-lessons-learned-and-cool-use-cases">https://github.com/jghoman/awesome-apache-airflow?tab=readme-ov-file#best-practices-lessons-learned-and-cool-use-cases</a> - awesome-airflow</li>
<li><a target="_blank" rel="noopener" href="https://medium.com/datamindedbe/cross-dag-dependencies-in-apache-airflow-a-comprehensive-guide-88cbc0bc68d0">https://medium.com/datamindedbe/cross-dag-dependencies-in-apache-airflow-a-comprehensive-guide-88cbc0bc68d0</a> - trigger，sensor，dataset，api 描述和应用</li>
<li><a target="_blank" rel="noopener" href="http://viplao.com/index.php/2024/10/26/%E5%A4%A7%E8%A7%84%E6%A8%A1%E8%BF%90%E8%A1%8C-apache-airflow-%E7%9A%84%E7%BB%8F%E9%AA%8C%E5%92%8C%E6%95%99%E8%AE%AD/">http://viplao.com/index.php/2024/10/26/%E5%A4%A7%E8%A7%84%E6%A8%A1%E8%BF%90%E8%A1%8C-apache-airflow-%E7%9A%84%E7%BB%8F%E9%AA%8C%E5%92%8C%E6%95%99%E8%AE%AD/</a> - 经验分享</li>
<li><a target="_blank" rel="noopener" href="https://yylives.cc/2024/02/08/what-we-learned-after-running-airflow-on-kubernetes-for-2-years/">https://yylives.cc/2024/02/08/what-we-learned-after-running-airflow-on-kubernetes-for-2-years/</a> - 经验分享</li>
</ul>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="http://example.com">Legacy</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://example.com/466764255/">http://example.com/466764255/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://example.com" target="_blank"></a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/airflow/">airflow</a></div><div class="post_share"><div class="social-share" data-image="https://wei-foun.github.io/img/cover47.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/558590641/"><img class="prev-cover" src="https://wei-foun.github.io/img/cover48.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">k8s整理</div></div></a></div><div class="next-post pull-right"><a href="/2133446919/"><img class="next-cover" src="https://wei-foun.github.io/img/cover46.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Linux 基础</div></div></a></div></nav><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/avatar.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Legacy</div><div class="author-info__description">冒险的生涯在召唤！</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">57</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">37</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">55</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">Live a life you will remember</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%84%E4%BB%B6%E4%BB%8B%E7%BB%8D"><span class="toc-number">1.</span> <span class="toc-text">组件介绍</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%9B%B8%E5%85%B3%E6%A6%82%E5%BF%B5"><span class="toc-number">1.1.</span> <span class="toc-text">相关概念</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86"><span class="toc-number">1.2.</span> <span class="toc-text">工作原理</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A7%92%E8%89%B2%E6%9D%83%E9%99%90"><span class="toc-number">2.</span> <span class="toc-text">角色权限</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%87%AA%E5%AE%9A%E4%B9%89-role-%E5%92%8C%E6%9D%83%E9%99%90"><span class="toc-number">2.1.</span> <span class="toc-text">自定义 role 和权限</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#api-%E8%AE%A4%E8%AF%81"><span class="toc-number">2.2.</span> <span class="toc-text">api 认证</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BF%9E%E6%8E%A5%E7%AE%A1%E7%90%86"><span class="toc-number">3.</span> <span class="toc-text">连接管理</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#connection-%E5%92%8C-hook"><span class="toc-number">3.1.</span> <span class="toc-text">connection 和 hook</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E6%9F%A5%E8%AF%A2"><span class="toc-number">4.</span> <span class="toc-text">数据查询</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%BB%E5%8A%A1%E6%B5%81"><span class="toc-number">5.</span> <span class="toc-text">任务流</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8C%85%E7%AE%A1%E7%90%86"><span class="toc-number">6.</span> <span class="toc-text">包管理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%BB%E5%8A%A1%E4%BE%9D%E8%B5%96%E5%85%B3%E7%B3%BB"><span class="toc-number">7.</span> <span class="toc-text">任务依赖关系</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#dag-%E7%AE%A1%E7%90%86"><span class="toc-number">8.</span> <span class="toc-text">dag 管理</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#dag-%E6%96%87%E4%BB%B6%E8%A7%A3%E6%9E%90"><span class="toc-number">8.1.</span> <span class="toc-text">dag 文件解析</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#k8s-executor"><span class="toc-number">9.</span> <span class="toc-text">k8s executor</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8F%98%E9%87%8F%E5%AE%89%E5%85%A8"><span class="toc-number">10.</span> <span class="toc-text">变量安全</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Task-%E5%88%86%E6%94%AF"><span class="toc-number">11.</span> <span class="toc-text">Task 分支</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8A%A8%E6%80%81%E4%BB%BB%E5%8A%A1"><span class="toc-number">12.</span> <span class="toc-text">动态任务</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Trigger-Rules"><span class="toc-number">13.</span> <span class="toc-text">Trigger Rules</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Setup-and-teardown"><span class="toc-number">14.</span> <span class="toc-text">Setup and teardown</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Sensor"><span class="toc-number">15.</span> <span class="toc-text">Sensor</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Xcom"><span class="toc-number">16.</span> <span class="toc-text">Xcom</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Ti-%E7%9A%84%E7%8A%B6%E6%80%81"><span class="toc-number">17.</span> <span class="toc-text">Ti 的状态</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Dag-demo"><span class="toc-number">18.</span> <span class="toc-text">Dag demo</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Scheduler-%E5%B7%A5%E4%BD%9C%E6%B5%81%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-%E2%80%94%E2%80%94-%E7%BA%AF%E6%96%87%E5%AD%97%E7%89%88"><span class="toc-number">19.</span> <span class="toc-text">Scheduler 工作流源码分析 —— 纯文字版</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Celeryexecutor-%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B"><span class="toc-number">20.</span> <span class="toc-text">Celeryexecutor 工作流程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8F%82%E8%80%83%E5%BC%95%E7%BA%BF"><span class="toc-number">21.</span> <span class="toc-text">参考引线</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/3930090917/" title="mysql-主备"><img src="https://wei-foun.github.io/img/cover55.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="mysql-主备"/></a><div class="content"><a class="title" href="/3930090917/" title="mysql-主备">mysql-主备</a><time datetime="2025-08-24T13:50:40.000Z" title="发表于 2025-08-24 21:50:40">2025-08-24</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2733267950/" title="redis-分布式锁"><img src="https://wei-foun.github.io/img/cover54.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="redis-分布式锁"/></a><div class="content"><a class="title" href="/2733267950/" title="redis-分布式锁">redis-分布式锁</a><time datetime="2025-08-24T08:14:44.000Z" title="发表于 2025-08-24 16:14:44">2025-08-24</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/3739994726/" title="虚拟化"><img src="https://wei-foun.github.io/img/cover53.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="虚拟化"/></a><div class="content"><a class="title" href="/3739994726/" title="虚拟化">虚拟化</a><time datetime="2025-08-23T10:43:26.000Z" title="发表于 2025-08-23 18:43:26">2025-08-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2554484522/" title="LVS"><img src="https://wei-foun.github.io/img/cover52.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="LVS"/></a><div class="content"><a class="title" href="/2554484522/" title="LVS">LVS</a><time datetime="2025-08-23T10:13:00.000Z" title="发表于 2025-08-23 18:13:00">2025-08-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/166210836/" title="gitlab-ci"><img src="https://wei-foun.github.io/img/cover51.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="gitlab-ci"/></a><div class="content"><a class="title" href="/166210836/" title="gitlab-ci">gitlab-ci</a><time datetime="2025-08-05T02:52:42.000Z" title="发表于 2025-08-05 10:52:42">2025-08-05</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url('https://wei-foun.github.io/img/cover47.jpg')"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2025 By Legacy</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="/js/search/local-search.js"></script><script>var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',preloader.endLoading())</script><div class="js-pjax"><script>function loadValine () {
  function initValine () {
    const valine = new Valine(Object.assign({
      el: '#vcomment',
      appId: 'MHzSjOElX9Cf5IJAfoNr4COL-gzGzoHsz',
      appKey: 'K3d5HK6zRMD2BINwstEANt7H',
      avatar: 'monsterid',
      serverURLs: '',
      emojiMaps: {"tv_doge":"6ea59c827c414b4a2955fe79e0f6fd3dcd515e24.png","tv_親親":"a8111ad55953ef5e3be3327ef94eb4a39d535d06.png","tv_偷笑":"bb690d4107620f1c15cff29509db529a73aee261.png","tv_再見":"180129b8ea851044ce71caf55cc8ce44bd4a4fc8.png","tv_冷漠":"b9cbc755c2b3ee43be07ca13de84e5b699a3f101.png","tv_發怒":"34ba3cd204d5b05fec70ce08fa9fa0dd612409ff.png","tv_發財":"34db290afd2963723c6eb3c4560667db7253a21a.png","tv_可愛":"9e55fd9b500ac4b96613539f1ce2f9499e314ed9.png","tv_吐血":"09dd16a7aa59b77baa1155d47484409624470c77.png","tv_呆":"fe1179ebaa191569b0d31cecafe7a2cd1c951c9d.png","tv_嘔吐":"9f996894a39e282ccf5e66856af49483f81870f3.png","tv_困":"241ee304e44c0af029adceb294399391e4737ef2.png","tv_壞笑":"1f0b87f731a671079842116e0991c91c2c88645a.png","tv_大佬":"093c1e2c490161aca397afc45573c877cdead616.png","tv_大哭":"23269aeb35f99daee28dda129676f6e9ea87934f.png","tv_委屈":"d04dba7b5465779e9755d2ab6f0a897b9b33bb77.png","tv_害羞":"a37683fb5642fa3ddfc7f4e5525fd13e42a2bdb1.png","tv_尷尬":"7cfa62dafc59798a3d3fb262d421eeeff166cfa4.png","tv_微笑":"70dc5c7b56f93eb61bddba11e28fb1d18fddcd4c.png","tv_思考":"90cf159733e558137ed20aa04d09964436f618a1.png","tv_驚嚇":"0d15c7e2ee58e935adc6a7193ee042388adc22af.png"},
      path: window.location.pathname,
      visitor: true
    }, null))
  }

  if (typeof Valine === 'function') initValine() 
  else getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js').then(initValine)
}

if ('Valine' === 'Valine' || !true) {
  if (true) btf.loadComment(document.getElementById('vcomment'),loadValine)
  else setTimeout(loadValine, 0)
} else {
  function loadOtherComment () {
    loadValine()
  }
}</script></div><script defer="defer" id="ribbon" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-ribbon.min.js" size="150" alpha="0.6" zIndex="-1" mobile="false" data-click="false"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>