<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>Redis 整理 | </title><meta name="keywords" content="redis"><meta name="author" content="Legacy"><meta name="copyright" content="Legacy"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Redis 概览  ​    redis 是一个高性能的 key-value 的非关系型数据库，支持丰富的数据结构，同时作为缓存应用还支持了数据的持久化，相比另一种内存型数据库 memcached 功能更多    对比参数 Redis Memcached    类型 1）支持内存   2）是一种非关系型数据库 1）支持内存  2）key-value 键值对形式  3）缓存系统   数据存储类型 1">
<meta property="og:type" content="article">
<meta property="og:title" content="Redis 整理">
<meta property="og:url" content="http://example.com/3714377604/index.html">
<meta property="og:site_name">
<meta property="og:description" content="Redis 概览  ​    redis 是一个高性能的 key-value 的非关系型数据库，支持丰富的数据结构，同时作为缓存应用还支持了数据的持久化，相比另一种内存型数据库 memcached 功能更多    对比参数 Redis Memcached    类型 1）支持内存   2）是一种非关系型数据库 1）支持内存  2）key-value 键值对形式  3）缓存系统   数据存储类型 1">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://wei-foun.github.io/img/cover30.jpg">
<meta property="article:published_time" content="2021-01-16T05:18:39.000Z">
<meta property="article:modified_time" content="2025-04-01T17:58:07.113Z">
<meta property="article:author" content="Legacy">
<meta property="article:tag" content="redis">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://wei-foun.github.io/img/cover30.jpg"><link rel="shortcut icon" href="/img/favicon.ico"><link rel="canonical" href="http://example.com/3714377604/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Redis 整理',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2025-04-02 01:58:07'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 5.3.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/avatar.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">48</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">30</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">45</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 文章</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 爱好收集</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://wei-foun.github.io/img/cover30.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/"></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 文章</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 爱好收集</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Redis 整理</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2021-01-16T05:18:39.000Z" title="发表于 2021-01-16 13:18:39">2021-01-16</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-04-01T17:58:07.113Z" title="更新于 2025-04-02 01:58:07">2025-04-02</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/redis-%E9%87%8D%E7%82%B9/">redis 重点</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Redis 整理"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h3 id="Redis-概览"><a href="#Redis-概览" class="headerlink" title="Redis 概览"></a>Redis 概览</h3><p><img src="https://static001.geekbang.org/resource/image/79/e7/79da7093ed998a99d9abe91e610b74e7.jpg" alt="img"> </p>
<p>​    redis 是一个高性能的 key-value 的非关系型数据库，支持丰富的数据结构，同时作为缓存应用还支持了数据的持久化，相比另一种内存型数据库 memcached 功能更多</p>
<table>
<thead>
<tr>
<th>对比参数</th>
<th>Redis</th>
<th>Memcached</th>
</tr>
</thead>
<tbody><tr>
<td>类型</td>
<td>1）支持内存   2）是一种非关系型数据库</td>
<td>1）支持内存  2）key-value 键值对形式  3）缓存系统</td>
</tr>
<tr>
<td>数据存储类型</td>
<td><strong>1）string  2）list  3）set  4）hash  5）sorted set（zset）</strong>有序集合</td>
<td>1）文本型  2）二进制类型</td>
</tr>
<tr>
<td>查询类型</td>
<td>1）批量操作  2）<strong>支持事务，但不具备原子性，因为不能回滚</strong>  3）每个类型有不同的 crud</td>
<td>1）crud  2）以及其他命令</td>
</tr>
<tr>
<td>附加功能</td>
<td>1）发布 / 订阅模式  2）主从分区  3）序列化支持  4）脚本支持</td>
<td>1）多线程服务支持</td>
</tr>
<tr>
<td>网络 IO 模型</td>
<td>1）单线程 + IO 多路复用  2）<strong>6 的版本开始支持多线程</strong>，但对于命令执行依然是单线程</td>
<td>1）多线程，非阻塞 IO 模式</td>
</tr>
<tr>
<td>事件库</td>
<td>自封装简易事件库 AeEvent</td>
<td>传统的 LibEvent 事件库</td>
</tr>
<tr>
<td>持久化</td>
<td>1）RDB  2）AOF</td>
<td>不支持</td>
</tr>
</tbody></table>
<p>​    redis 严格意义上来说并不完全是单线程，只对于 redis 的网络 IO 和键值读写是通过单线程来完成的，而 redis 的其他功能，持久化、异步删除、集群数据同步等，都是由额外的线程做单独处理。而 <strong>redis 的数据操作快速，主要是使用 IO 多路复用的机制，避免了 socket 的阻塞</strong></p>
<h3 id="Redis-数据类型及使用场景"><a href="#Redis-数据类型及使用场景" class="headerlink" title="Redis 数据类型及使用场景"></a>Redis 数据类型及使用场景</h3><p>​    <strong>string（字符串）：可以用实现简单的 KV 键值对存储，比如计数器功能进行统计，缓存用户 session 信息</strong></p>
<p>​    <strong>list（列表）：支持双端操作，可用作双端队列，比如用户的关注，粉丝列表，或是作为消息队列</strong></p>
<p>​    <strong>hash（哈希表）：用来存储彼此相关信息的键值对</strong></p>
<p>​    <strong>set（集合）：存储不重复元素，用来实现去重，比如存储标签</strong></p>
<p>​    <strong>sorted set（有序集合）：可以用来实现信息的排行榜功能</strong></p>
<p><img src="https://wei-foun.github.io/img/redis-%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E5%92%8C%E7%BB%93%E6%9E%84.jpg" alt="img"></p>
<h4 id="五种类型的底层实现"><a href="#五种类型的底层实现" class="headerlink" title="五种类型的底层实现"></a>五种类型的底层实现</h4><p>​    <strong>string：使用 long 类型整数 或 sds（simple dynamic string，简单动态字符串），可以存储文本或二进制的数据。sds 会分为三部分，alloc 表示剩余实际分配长度，len 来记录字符串的长度，这样就能以 O(1) 的时间来查询到字符串的长度值，真正字符串数据存在在 buff 中，字符串的末尾会加一个字符 <code>\0</code> 表示结束</strong></p>
<p>​    当存储的数据是有符号的整数，会使用 long 类型存储，而存储字符则会使用 sds 存储，使用 sds 存储会增加内存消耗，因为 alloc 会占用 4 个字节，len 也会占用 4 个字节，在 buf 中还有一个 <code>\0</code> 占用一个字节</p>
<p><img src="https://wei-foun.github.io/img/redis-sds.jpg" alt="img"></p>
<p>​    <strong>list：使用 ziplist 或 double linked list，3.2 版本中又增加了 quicklist，quicklist 可以看作是前两者的结合</strong></p>
<p>​    <strong>ziplist（压缩列表），同样是一个连续地址的结构，相比起数组类型存储要更加节省内存</strong>，因为数组中每一个元素的大小都是相同的，<strong>数组创建后每一个元素都是固定 20 字节</strong>；ziplist 是 <strong>每一个元素的大小全部根据元素的真实大小来存储</strong></p>
<p>​    同时，<strong>压缩列表的头部有三个字段，zlbytes 即列表的字节长度，zltail 即列表尾部偏移量，zllen 即压缩列表中元素的个数，同时在列表最后还有一个字段，zlend 即表示列表结束位置，zlend 默认值是 255</strong>。那么对于压缩列表的查询第一个元素和最后一个元素，就可以直接根据头三个字段去查询得到，也就是说 <strong>压缩列表的头尾两个元素的查找都是 O(1) 的，其他位置的查找依然是 O(n)</strong></p>
<p><img src="https://static001.geekbang.org/resource/image/f6/9f/f6d4df5f7d6e80de29e2c6446b02429f.jpg?wh=3457*972" alt="img"></p>
<p>​    压缩列表中每个 entry 元素有 4 个部分：encoding 是编码方式，占用 1 字节。len 表示 entry 的长度，占用 4 字节。key 则是实际存储的数据。prev_len 表示前一个 entry 的长度，会占用 1 或 5 个字节，如果值是 1 个字节表示前一个 entry 长度小于 254 个字节</p>
<p>​    <strong>一个列表中所有字符串的长度小于 64 个字节，或者保存的元素数量小于 512 个都会使用 ziplist ，否则使用 double linked list</strong></p>
<p>​    <strong>hash：使用 ziplist 或 hashtable</strong></p>
<p>​    <strong>set：使用 intset 或 hashtable</strong></p>
<p>​    <strong>sorted set：使用 skiplist 跳（跃）表</strong>，简单理解就是通过链表上添加多级索引，利用类似二分法的方式进行查找，每一级索引的节点数都是上一级的一半，<strong>查找一个元素的时间复杂度会是 O(logn)</strong></p>
<p><img src="https://www.pianshen.com/images/573/e2be2c76594df76ebddfe9c3c4e516a5.png" alt="在这里插入图片描述"> </p>
<p>​    注意：数据类型的底层数据结构在时间复杂度上可能是存在区别的，比如 哈希表 结构的 O(1)，压缩链表、双向链表以及整数数组的结构是 O(n)，而跳表的结构是 O(logn)，但是 redis 的数据类型都支持非常丰富的命令，所以具体的时间复杂度并不是一定和该数据使用的数据结构是一致的</p>
<p>​    比如 hash 的命令，hset 或 hget 这样的 <strong>单个元素操作</strong>，时间复杂度就是数据结构的时间复杂度 O(1)，但 hash 的操作还支持 hmset 以及 hmget 这样一次可以进行多个元素的操作情况下，<strong>时间复杂度就随着元素个数而改变</strong>，就从 O(1) 变成了 O(m)</p>
<p>​    redis 除了支持多个元素操作，有的类型还可以进行范围的查询操作，比如 hash 有 hgetall 和 set 的 smembers 来返回所有的元素，list 有 lrange 和 zset 有 zrange 来返回部分元素，这些 <strong>范围的操作，都需要通过遍历进行，在时间复杂度上就会是 O(n)</strong></p>
<h4 id="全局哈希表"><a href="#全局哈希表" class="headerlink" title="全局哈希表"></a>全局哈希表</h4><p>​    redis 通过全局哈希表来实现快速的键值访问，虽然说是哈希表，但实际上一个数组，每个元素称为是一个哈希桶（entry），每个 entry 实际上保存了 *key 和 *value 两个指针，来指向实际设置的键值。同时 entry 里还有一个 *next 用来指向下一个 entry</p>
<p><img src="https://static001.geekbang.org/resource/image/1c/5f/1cc8eaed5d1ca4e3cdbaa5a3d48dfb5f.jpg?wh=1773*875" alt="img"></p>
<p>​    entry 的三个指针都是 8 个字节，也就是说全局哈希表中每一个 entry 最少是 24 个字节</p>
<p>​    至于说是至少 24 个字节，是因为 redis 再分配内存时，实际是 jemalloc 这个库进行的操作，<strong>jemalloc 分配内存会根据申请的字节数 n，找到比 n 大的最接近 n 的 2 次幂的数作为分配空间，以此减少频繁分配的次数。也就说 entry 申请时需要 24 个字节，但是 jemalloc 实际上会去分配 2^5^ 即 32 个字节</strong></p>
<h4 id="数据类型的常用命令"><a href="#数据类型的常用命令" class="headerlink" title="数据类型的常用命令"></a>数据类型的常用命令</h4><p>​    string：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">set key value       # 设置指定 key 的值，如果 key 存在，覆盖 value</span><br><span class="line">get key             # 获取指定 key 的值</span><br><span class="line">getrange key start end           # 获取 key 的 start 到 end 位置的子字符串</span><br><span class="line">mset key1 value1 key2 value      # 批量设置多个 key</span><br><span class="line">mget key1  key2     # 批量获取多个 key</span><br><span class="line">incr key            # 对字符串的数字自增 +1</span><br><span class="line">decr key            # 对字符串的数字自减 —1</span><br><span class="line">incrby key value    # 指定要增加的 value</span><br><span class="line">decrby key value    # 指定减去 value 的值</span><br><span class="line">setnx key value     # 只有在 key 不存在时，才创建 key 和 value，如果 key 存在，不会覆盖 value</span><br><span class="line">setex key seconds value          # 设置 key 的 过期时间</span><br></pre></td></tr></table></figure>
<p>​    list：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">lpush key value     # 在列表头部插入 value，可以指定多个 value 一起插入</span><br><span class="line">lpop key            # 在列表的头部移除一个元素并返回</span><br><span class="line">rpush key value     # 在列表尾部插入 value，可以指定多个 value 一起插入</span><br><span class="line">rpop key            # 在列表的尾部移除一个元素并返回</span><br><span class="line">lindex key index    # 通过 index 索引获取列表 key 的指定元素</span><br><span class="line">blpop key timeout   # 从列表 key 的头部移除一个元素，没有的话进行阻塞，直到超过 timeout 或有元素可以返回，brpop 同理</span><br><span class="line">lpushx key value       # 将 value 从已存在的列表头部加入，如果列表不存在，命令不会生效</span><br><span class="line">lrem key count value   # 从列表中移除指定 count 数量的 value</span><br><span class="line">lset key index value   # 通过列表索引将 value 进行插入</span><br><span class="line">llen key               # 获取列表的长度</span><br><span class="line">brpoplpush source destination timeout   # 从 source 列表尾部移除一个元素加入到 destination 列表的头部，没有元组可以操作就阻塞，直到超出 timeout 或有元素可以操作</span><br></pre></td></tr></table></figure>
<p>​    hash：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">hset key field value      # 给哈希表 key，设置 field 字段，值为 value</span><br><span class="line">hget key field            # 获取哈希表 key，field 字段的值</span><br><span class="line">hmset key field value field1 value1      # 批量设置多个字段和值</span><br><span class="line">hmget key field field1    # 批量获取多个字段的值</span><br><span class="line">hgetall key               # 获取哈希表中所有的键值对</span><br><span class="line">hkeys key                 # 获取哈希表中所有的字段</span><br><span class="line">hvals key                 # 获取哈希表中所有的值</span><br><span class="line">hexists key field         # 判断哈希表中指定的 key 是否存在</span><br><span class="line">hlen key                  # 获取哈希表中字段的数量，键值对的数量</span><br><span class="line">hsetnx key field value    # 只有字段 field 不存在时，才设置指定的 value</span><br></pre></td></tr></table></figure>
<p>​    set：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sadd key member1 [member2]    # 向集合加入一个或多个成员</span><br><span class="line">scard key                     # 获取集合中成员的个数</span><br><span class="line">smembers key                  # 获取集合中所有的成员</span><br><span class="line">spop key                      # 随机从集合中移除一个元素并返回</span><br><span class="line">srem key member1 [member2]    # 从集合中指定移除一个或多个成员</span><br><span class="line">srandmembers key [count]      # 随机获取集合中的一个值，可以通过 count 指定获取值的个数</span><br></pre></td></tr></table></figure>
<p>​    sorted set：与 set 不同，<strong>每一个元素会关联一个 double 类型的分数，redis 通过分数实现从小到大的排序</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">zadd key score1 member1 [score2 member2]    # 向有序集合中插入一个或多个成员，如果成员已存在则更新分数</span><br><span class="line">zcarf key                                   # 获取有序集合的成员数</span><br><span class="line">zcount key min max                          # 计算分数在 min 和 max 之间的成员个数</span><br><span class="line">zrange key start stop [withscores]          # 通过索引获取指定区间的成员，使用 withscores 参数则会将成员对应的分数也返回</span><br><span class="line">zrank key member                            # 返回有序集合中指定成员的索引</span><br><span class="line">zrem key member1 [member2]                  # 移除有序集合中一个或多个成员</span><br><span class="line">zrangebyscore key min max [withscores] [limit offset count]   # 返回分数在 min 到 max 之间的成员，返回所有成员使用 zrangebyscore key -inf +inf withscores</span><br><span class="line">zrevrange key start end                     # 让索引在 start 和 end 之间的成员，分数由高到低返回</span><br><span class="line">zrevrangebyscore key max min [withscores]   # 返回指定分数在 max 到 min 之间的成员，由高到低排序</span><br><span class="line">zscore key member                           # 返回有序集合中成员的分数</span><br></pre></td></tr></table></figure>
<h4 id="补充：RedisObject"><a href="#补充：RedisObject" class="headerlink" title="补充：RedisObject"></a>补充：RedisObject</h4><p>​    redis 支持多个不同类型的数据存储，不同的数据类型都存在出了实际存储数据之外的元数据要存储，元数据可能会存储最后一次访问时间，引用的次数等等，所以 redis 使用了一个 RedisObject 的结构来统一元数据，以及实际数据的指向</p>
<p>​    对于一个 RedisObject 结构，包含了 8 个字节的元数据部分，以及 8 字节的实际数据位置指针</p>
<p>​    对于 redis 中 str 类型，这个 RedisObject 结构做了专门的设计，如果 str 类型存储的是 long 的整数，那么 RedisObject 的指针部分，其实会被直接复制为整数数据，这样就省去了指针的空间。如果存储的字符类型，redis 又设计两个情况处理，如果字符串小于等于 44 个字节，在 RedisObject 会和 sds 连续存储，来避免内存碎片。反之，则就将 sds 单独存储</p>
<p><img src="https://static001.geekbang.org/resource/image/ce/e3/ce83d1346c9642fdbbf5ffbe701bfbe3.jpg?wh=3072*1938" alt="img"></p>
<p>​    </p>
<h3 id="持久化"><a href="#持久化" class="headerlink" title="持久化"></a>持久化</h3><p>​    对于内存型的数据库而言，redis 用作缓存时，就必定要面临数据因为断点造成服务宕机，数据丢失问题，所以 redis 通过两种方式来实现对持久化的支持</p>
<p>​    <strong>RDB（快照方式，redis database）：就是将某一时刻的数据通过二进制方式写入到文件中（dump.rdb），注意这个 RDB 的快照是一个 全量快照，目的就是为了不让快照时丢失数据</strong></p>
<p>​    <strong>AOF（文件追加，append only file）：默认情况下 redis 不开启 AOF 方式，相比 RDB 而言，AOF 会将执行的每一个写命令都追加写入到文件中（appendonly.aof）</strong></p>
<h4 id="RDB"><a href="#RDB" class="headerlink" title="RDB"></a>RDB</h4><p>​    <strong>redis 默认使用是 RBD 的持久化方式</strong>，可以通过手动或自动来触发持久化操作，手动方式可以通过 <code>save</code> 和 <code>bgsave</code> 两种命令触发，自动触发则是通过对配置文件进行配置，达到条件时自动触发</p>
<p>​    <strong>SAVE：</strong></p>
<p>​    <strong>虽然 6 的版本开始 redis 支持了多线程， 但是对于命令的执行依旧是单线程的形式</strong>，所以当一个客户端对 redis 服务发送 <code>save</code> 命令后，其他客户端此时无法对该 redis 服务进行操作，全部都进入到 <strong>阻塞</strong> 状态</p>
<p><img src="https://wei-foun.github.io/img/redis-save.jpg" alt="img"> </p>
<p>​    <strong>BGSAVE：</strong></p>
<p>​    可以看作是 <code>save</code> 命令的一个优化，<code>bgsave</code> 命令发起持久化操作，redis 主进程会先调用 <strong>fork 创建一个子进程</strong>，并将生成 rdb 文件的持久化操作交给该子进程来实现，此时 <strong>redis 服务不会被阻塞</strong> 住，依然接收其他客户端请求并响应</p>
<p>​    <strong>补充：bgsave 子进程虽然不会阻塞主进程，但是这仅限于读操作</strong>。然而对于 <strong>写操作，bgsave 在进行全量快照的时，redis 会将涉及写操作的数据进行拷贝，产生一个原数据的副本，bgsave 快照仅仅是对这个副本进行快照备份</strong>，所以 redis 的主线程不会因为 bgsave 而对写操作产生影响</p>
<p>​    另外 <strong>RDB 的快照只是在第一次进行一次 全量快照，后续的快照则是通过 增量快照 来备份数据</strong>。目的是防止短期内大量的全量快照，会造成磁盘压力增加导致性能损失，同时后续的增量快照会去判断在全量快照后，对之后被修改的数据进行增量快照，但是如果数据量很大，即使是增量快照同样会直接影响到性能，并且每次去标记判断数据是否被修改，还会需要额外的空间</p>
<p>​    <img src="https://wei-foun.github.io/img/redis-bgsave.jpg" alt="img"> </p>
<p>​    对于自动触发，则是在 redis 的 conf 中配置 save 选项，当条件满足后会自动触发，使用 <code>bgsave</code> 命令去进行持久化</p>
<p>​    save 的配置项为：<code>save m n</code>，m 表示秒数，n 表示次数，整个配置表示在 m 秒中执行 n 次命令就执行一次持久化，默认在 redis.conf 配置文件中有三种状态的持久化配置，其中任何一种状态满足就会自动去触发持久化操作</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">save 900 1</span><br><span class="line">save 300 10</span><br><span class="line">save 60 10000</span><br></pre></td></tr></table></figure>
<p>​    每次创建 rdb 文件后，服务器会自动将时间计数器和次数计数器置为零，并从新开始计数</p>
<p>​    <strong>恢复：</strong></p>
<p>​    当 redis 服务出现问题或宕机，再次启动后会 <strong>自动检测 dump.rdb 文件，通过加载来进行数据恢复</strong></p>
<h4 id="AOF"><a href="#AOF" class="headerlink" title="AOF"></a>AOF</h4><p>​    与 RDB 一样都是通过写入文件来创建持久化，但 <strong>AOF 默认是不开启的</strong>，所以要是用 AOF 持久化，需要设置配置项，在 <strong>conf 文件中设置 <code>appendonly yes</code> 开启 AOF</strong></p>
<p>​    对于 <strong>AOF 写入，实际上分成了两个步骤，首先操作命令会先被执行，再被写入到 <code>aof_buf</code> 缓存中，然后 redis 通过配置项中的设置来做不同的策略将缓冲区的命令继续追加写入到文件中</strong></p>
<p><img src="https://wei-foun.github.io/img/redis-aof.jpg" alt="img"></p>
<p>​    <strong>AOF 之所以先在内存中执行命令写入后，再去进行磁盘的追加写进行日志记录，其目的是为了防止在日志文件中记录不必要的错误命令，造成额外的存储与检查开销，以及在进行日志恢复时可能出现的错误</strong>；同时另一个好处是，”后写” 日志将不会阻塞命令的写入执行</p>
<p>​    <strong>但是 AOF 如果执行完命令，还没来及写日志就宕机，且 redis 不是做缓存而是直接作为数据库的话，就会导致数据丢失并无法恢复</strong>；并且，如果 AOF 在主线程中去执行日志写入，虽然不会阻塞当前命令，但是如果磁盘压力较大的话，还是会导致后续的命令执行会出现阻塞状态</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">appendfsync always</span><br><span class="line"># always 表示命令写入到 aof_buf 缓冲区后，立马调用 fsync 命令进行同步追加写到文件</span><br><span class="line"></span><br><span class="line">appendfsync everysec</span><br><span class="line"># everysec 表示先调用系统 write 操作，然后返回。fsync 的操作则由专门的线程每隔 1 秒执行一次文件写入</span><br><span class="line"></span><br><span class="line">appendfsync no</span><br><span class="line"># no 表示调用 write 后，不会进行 aof 文件的同步，同步操作由操作系统自己负责，周期最长为 30 秒</span><br></pre></td></tr></table></figure>
<p>​    always 对整体性能影响最大，会占用较多 IO 资源，因为 always 某种意义上其实 AOF 的两个写入阶段变成了一个阶段，类似命令写入到 buf 中就立即执行了文件的写入，显然对性能影响会较大，但是在数据安全性上，相比其他方式也更高</p>
<p>​    everysec 相对 always 来说不是立刻的实时操作，隔离了两个写入阶段，对真正的文件写入利用子线程做一秒一次的定时写入，所以对性能影响相对较小，但是数据安全性上就可能存在丢失一秒的数据</p>
<p>​    no 则是在 everysec 上更加分离开两个阶段，将 buf 的命令写入交给系统来控制，但在数据安全性上也最低</p>
<p>​    另外需要注意：<strong>everysec 和 no，调用 write 来写入缓冲区时，会触发延迟写机制，不会阻塞服务</strong>，当命令写完后会返回。而 <strong>always 则是直接用 fsync 强制执行磁盘同步，所以会阻塞住</strong>，直到缓存区的内容写入到磁盘文件中</p>
<p><img src="https://wei-foun.github.io/img/redis-aof%E7%AD%96%E7%95%A5.jpg" alt="img"></p>
<p>​    <strong>重写机制：</strong></p>
<p>​    重写机制本身并不是真的完全重写，而 <strong>是通过策略进行优化通过新的文件覆盖旧文件实现</strong></p>
<p>​    因为 AOF 是追加写入方式，所以会随着命令的不断写入，导致 AOF 文件的不断增大占用更多的磁盘空间，比如对一个 key 反复设置不同的 value，而真正有用的只有最后一次设置的 value，而之前的设置就都是无用的命令；又或者操作的 key 已经过期被删除，那文件记录的命令也是无效命令，以及对一个列表的元素添加命令是分开执行，而不是整合在一个命令，这样的情况都会额外增加文件的空间</p>
<p><img src="https://wei-foun.github.io/img/redis-%E9%87%8D%E5%86%99%E6%9C%BA%E5%88%B6.jpg" alt="img"></p>
<p>​    为了对此进行优化 redis 提供重写机制，将上面提到的重写策略进行优化，可以 <strong>通过手动启动使用命令 <code>bgrewriteaof</code></strong>，自动启动同样是在配置文件中进行设置</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">auto-aof-rewrite-percentage 100</span><br><span class="line"># percentage 表示 aof 文件距离上次文件增长的超过多少的百分比来触发重写</span><br><span class="line"></span><br><span class="line">auto-aof-rerite-min-size 64mb</span><br><span class="line"># min-size 表示 aof 文件体积最小达到多少来触发重写</span><br></pre></td></tr></table></figure>
<p>​    当满足所有设置的条件，会自动触发 AOF 重写，redis 会扫描整个实例的数据，重新生成一个 aof 文件</p>
<p>​    <strong>进程 AOF 持久化时，redis 的主进程会 fork 出一个子进程来做操作，在此期间 redis 是阻塞状态，且 fork 出的子进程与主进程是公用一个内存的，为了避免 fork 期间阻塞无法接收写命令</strong></p>
<p>​    fork 完成后， <strong>redis 会开启 <code>aof_rewrite_buf</code> 重写缓冲区，由于 fork 的子进程和主进程是共享内存空间的，所以 fork 创建完子进程后，子进程会去拷贝数据到 <code>aof_rewrite_buf</code>，这样即不会阻塞主线程接收命令，同时也将数据做了一次备份，来确保数据不丢失</strong></p>
<p><img src="https://wei-foun.github.io/img/redis-%E9%87%8D%E5%86%99%E8%BF%87%E7%A8%8B.jpg" alt="img"></p>
<p>​    主进程会从 <code>aof_rewrite_buf</code> 获取命令根据重写策略来写入到子进程创建的 AOF 文件，随后利用这个新的文件将原本的 AOF 文件进行替换</p>
<p>​    <strong>补充：</strong>redis 的 aof 重写之所要创建一个新的 aof 文件，是因为如果重写机制是在原 aof 上做操作，那么最直接的问题就是主进程会和 fork 的子进程会产生操作的竞争，那么解决竞争问题就势必会影响主进程的性能；其次，使用同一个 aof 文件的话，也存在另一个问题，如果 aof 重写过程中出现错误，整个文件就基本作废了，那么无法在恢复到原来的数据</p>
<p>​    <strong>恢复：</strong></p>
<p>​    aof 实现恢复前，redis 需要先创建一个不带网络连接的伪客户端来实现，通过这个伪客户端来执行 aof 文件中的命令，将数据进行还原恢复。这意味着如果 aof 命令日志文件较大，那么需要执行的命令就会很多，要进行恢复的话就会要缓慢一些，从而影响到正常使用</p>
<p><img src="https://wei-foun.github.io/img/aof-%E6%81%A2%E5%A4%8D.jpg" alt="img"></p>
<p>​    需要注意的是，如果 <strong>同时使用了 RDB 和 AOF 两种持久化方式，那么在进行恢复时则是优先使用 AOF 文件</strong> 来进行恢复，如果没有开启 AOF 则就是加载读取 RDB 的文件来恢复</p>
<h4 id="两者的优缺点"><a href="#两者的优缺点" class="headerlink" title="两者的优缺点"></a>两者的优缺点</h4><p>​    <strong>RDB 的优点：</strong></p>
<p>​    <strong>1）文件体积会更小，因为文件内容是二进制存储的</strong></p>
<p>​    <strong>2）恢复速度要更快</strong>，能够很快的读取到数据直接恢复</p>
<p>​    <strong>RDB 的缺点：</strong></p>
<p>​    <strong>1）数据容易存在丢失，因为都是 RDB 持久化保存的都是某一时刻上的数据快照</strong>，如果在写入文件时出现异常崩溃，在进行恢复期间，无法接受和响应就容易造成数据丢失</p>
<p>​    <strong>2）性能和资源消耗更多</strong>，在 bgsave 方式下需要创建额外的进程单独执行文件写入，在持久化期间会消耗大量 CPU 和 内存资源，所以不能频繁地去进行备份</p>
<p>​    <strong>3）可能存在不同版本的 RDB 文件不兼容的情况</strong></p>
<p>​    <strong>AOF 的优点：</strong></p>
<p>​    <strong>1）数据完整性更好</strong>，追加写入命令的方式确保了完整性，<strong>减少了数据恢复时的丢失率</strong>，将数据丢失控制在秒级别</p>
<p>​    <strong>2）易读性更好， AOF 存储的原生命令使得可读性要比 RDB 的二进制要强</strong></p>
<p>​    <strong>AOF 的缺点：</strong></p>
<p>​    <strong>1）文件体积更大</strong>，命令都是直接写入文件，即便有重写机制，所生成的文件依旧比 RDB 要大，且在数据 <strong>恢复速度上也要比二进制的 RDB 要慢</strong></p>
<p>​    2）在 everysec 方式下，每隔一秒的写入，容易造成磁盘 IO 变高，降低整体性能</p>
<h4 id="混合持久化"><a href="#混合持久化" class="headerlink" title="混合持久化"></a>混合持久化</h4><p>​    顾名思义，就是将 <strong>RDB 与 AOF 两种持久化方式的混合</strong>，这是在 redis 4 的版本之后新增的功能，<strong>通过在配置文件的 <code>aof-use-rdb-preamble</code> 来设置开启，混合持久化的方式也是使用 AOF 的 <code>bgrewriteaof</code></strong></p>
<p>​    不过持久化的文件很特别，<strong>首先 fork 出的子进程会将缓存区的命令通过 RDB 的形式写入到 AOF 文件中，然后再将重写缓存区内的命令增量写入 AOF，也就是说混合持久化模式下，生成的文件也包含了两种格式</strong></p>
<p>​    所以混合持久化的方式中，将全量和增量备份进行了隔离，全量快照依旧是使用 RDB，而此之后增量的部分利用 AOF 来记录修改的数据。这样既避免了全量快照频繁操作下影响性能，同时使用 AOF 记录增量也避免了 AOF 的文件过大。最后当进行第二次的全量快照时，AOF 的记录就会被清空，因为第二次的全量快照记录所有此前更改后的数据</p>
<p>​    混合持久化兼容了 RDB 与 AOF 的优缺点，但是混合持久化默认也是不开启的，且混合持久化的文件在 4 之前的版本也无法识别读取</p>
<p>​    <strong>总结：</strong></p>
<p>​    <strong>如果数据不允许丢失，使用混合持久化会是最好的选择；如果允许分钟级数据丢失，使用 RDB 的效率和恢复都比较好；如果只是使用 AOF，应该优先选择 everysec 的配置</strong></p>
<h3 id="Redis-主从模式"><a href="#Redis-主从模式" class="headerlink" title="Redis 主从模式"></a>Redis 主从模式</h3><p>​    redis 的高可用，首要的两个指标就是数据尽可能少的丢失，同时服务要尽可能少中断。前者 redis 已经有了 RDB 和 AOF 来负责，对于服务中断问题，redis 的做法是增加副本，将一份数据拷贝给多个 redis 实例，如果某个单点故障，其他实例依然能够提供服务，即通过集群来避免服务异常中断</p>
<p>​    <strong>redis 的主从模式其实就是双实例，主从库采用的是 读写分离 的方式</strong>。对于所有的读操作，请求和访问主库，也可以访问从库；但是 <strong>对于写操作，首先需要在主库上执行，由主库将写操作同步发送给从句</strong>，从库执行得到新数据</p>
<p>​    之所以将写操作分离开，其实是如果一个客户端对一个 key 修改了多次，而恰好又都是发给了不同的实例，那就会导致各个实例上的数据不一致</p>
<p><img src="https://wei-foun.github.io/img/redis-%E4%B8%BB%E4%BB%8E.jpg" alt="img"></p>
<p><strong>主从配置：</strong></p>
<p>​    redis 的主从配置并不复杂，对于主库来说并不需要进行配置修改，只需要在从库的配置文件中加上 <code>slaveof 主库的 ip 地址 主库的端口</code> 即可</p>
<p>​    假设主库的端口是 6379，使用 cp 命令拷贝默认的 redis.conf 文件并将新文件命名为 redis-6379.conf，然后通过 <code>sed &quot;s/6379/6380/g&quot; redis-6379.conf &gt; redis-6380.conf</code>，linux 的 sed 命令会将 redis-6379.conf 中全局所有的 6379 替换为 6380，然后保存到文件 redis-6380.conf 中，同样的方法可以创建 redis-6381.conf 的配置，这样就有了两个从库</p>
<p>​    然后，可以通过 linux 的 echo 命令添加从库配置 <code>echo &quot;slaveof 127.0.0.1 6379&quot; &gt;&gt; redis-6380.conf</code>，这样就在 6380 中添加了主库的地址和端口，同样的操作给 6381 的配置文件，最后各自通过配置文件运行启动 redis-server 实例</p>
<p>​    运行后，通过客户端命令 <code>redis-cli -p 6379 info replication</code>，可以查看到主库的主从同步信息</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">role:master</span><br><span class="line">connected_slaves:2</span><br><span class="line">slave0:ip=127.0.0.1,port=6380,state=online,offset=140,lag=1</span><br><span class="line">slave1:ip=127.0.0.1,port=6381,state=online,offset=140,lag=1</span><br></pre></td></tr></table></figure>
<p>​    同样可以查看从库的主从信息，只需要将 <code>redis-cli</code> 命令中的 <code>-p</code> 端口改为从库端口 <code>redis-cli -p 6380 info replication</code> </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">role:slave</span><br><span class="line">master_host:127.0.0.1</span><br><span class="line">master_port:6379</span><br><span class="line">master_link_status:up</span><br><span class="line">master_last_io_seconds_ago:1</span><br><span class="line">master_sync_in_progress:0</span><br><span class="line">slave_repl_offset:238</span><br><span class="line">slave_priority:100</span><br><span class="line">slave_read_only:1</span><br><span class="line">connected_slaves:0</span><br></pre></td></tr></table></figure>
<p><strong>主从库的同步过程中会有三个阶段：</strong></p>
<p>​    <strong>1）从库向主库发出连接， 请求进行同步</strong>。首先，从库需要执行 <code>replicaof 172.16.19.3 6379</code></p>
<p>​    然后，从库会给主库发送 psync 命令，并携带 runID 和 offset，由于第一次做同步，从库不知道主库的唯一实例 ID，所以 runID 是 ？，同时 offset 的值为 -1 表示第一次拷贝</p>
<p>​    主库收到 psync 后回复 fullresync 响应表示第一次拷贝采用的全量复制，并且携带自己的唯一 ID，以及自己当前的复制进度 offset</p>
<p>​    <strong>2）主库通过 bgsave 生成 RDB 文件，并同步给从库</strong>。从库接收后，清空本地数据，并加载主库发送的 RDB，实现一致性</p>
<p>​    在主库同步文件给从库期间，主库自己不会被阻塞，依然接收请求。这也意味着发送给从库的 RDB 不会包含发送期间主库执行所产生的新数据，为了确保一致性，主库会将在生成 RDB 后的写命令都存放在 replication buffer 中</p>
<p>​    <strong>3）当从库接收了主库 RDB 后，主库会将 replication buffer 中记录的修改一并发给从库，从库只要重新执行操作，就能实现主从库的数据同步</strong></p>
<p><img src="https://wei-foun.github.io/img/redis-%E4%B8%BB%E4%BB%8E%E5%90%8C%E6%AD%A5.jpg" alt="img"></p>
<p>​    由此可见，在主从同步的过程中，对主库的压力会较大，主库不但要自己生成 RDB，还需要通过网络传输这个文件。如果在一个集群中，从库节点数量很多，全部都关联主库的话，主库在 fork 创建子进程并生成 RDB 的消耗会很大，而且 fork 这一操作还会伴随阻塞。而就传输而言，RDB 文件也会直接占用网络带宽</p>
<p>​    所以在集群架构下，要分摊掉主库的压力，可以使用级联从库来实现，即不让所有的从库实例全部关联自主库，让内存和性能较好的实例做主库的从库，其余从库各自以级联方式去关联到上层从库</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">				  		|--- 从库</span><br><span class="line">				  		|					 |--- 从库</span><br><span class="line">客户端 ----------------- 主库 -------- 从库 ------|</span><br><span class="line">				  		|					 |--- 从库</span><br><span class="line">				  		|--- 从库</span><br></pre></td></tr></table></figure>
<p>​    级联主从的 “主-从-从” 方式解决了 redis 主库的压力，但是网络阻塞或是主从断联的问题依然存在。2.8 版本之前 redis 主从在断开后，从库会重新与主库在进行一次全量拷贝，这使得整个动作的开销非常大</p>
<p>​    2.8 版本之后，主从库采用了增量拷贝的方式来对连接恢复后继续进行数据同步。前面说到，主从库实现数据同步时，主库会利用 replication buffer 去做增量的写操作记录，来将同步时接收的数据在 RDB 发送给从库后自己接收的写操作</p>
<p>​    而为了解决主从之间因为网络问题导致断连，使得恢复后同步数据，<strong>主库还有一个缓冲区 repl_backlog_buffer，该缓冲区会在主从断开后，记录恢复前主库接收的写操作，该缓冲区的目的是为了找出连接恢复后，主从之间命令执行的差异，防止连接恢复后从库做全量的拷贝</strong></p>
<p>​    <strong>repl_backlog_buffer 是一个环型的缓冲区，会记录两个指针位置，一个是主库自己会记录自己写到的位置，另一个是从库记录的自己写到的位置</strong></p>
<p><img src="https://wei-foun.github.io/img/redis-repl_backlog_buffer.jpg" alt="img"></p>
<p>​    随着命令的写入执行，repl_backlog_buffer 中主库的位置就会往后移动，那么新的位置与初始位置的偏移量就是 master_repl_offset，同理，对应从库也就是 slave_repl_offset，两个偏移量都随着命令执行而不断增加</p>
<p>​    当主从网络连接突然断开，在恢复后。从库会先发 psync 命令，同时携带自己当前的 slave_repl_offset 给主库，因为主从网络连接断开后，主库依然在接受命令，所以自己在 repl_backlog_buffer 缓冲区上的位置会继续往后移动，当主库根据自己的 master_repl_offset 和从库的 slave_repl_offset 判断偏移量的差距后，表面在网络断开和恢复期间，主库接收的命令是哪部分，此时主库再将两个偏移量差的部分同步给从库，由此实现断联恢复后数据的一致性</p>
<p>​    <strong>注意：</strong>repl_backlog_buffer 和 InnoDB 的 redo log 非常相似，所以共同存在的一个问题就是，一旦 repl_backlog_buffer 的空间写满了，主从之间连接还没恢复，那么主库的位置会继续往后移动，也就意味着会擦除数据来留出位置给新的数据。如果从库没有与主库重新连接上，或者从库的处理性能又比较慢跟不上主库新写入的数据速度，那就非常容易造成数据丢失或不一致</p>
<p>​    所以对于 repl_backlog_buffer 的缓存大小设置就需要仔细设置，一般可以设置 repl_backlog_size = 缓冲空间大小 * 2 </p>
<h3 id="哨兵机制"><a href="#哨兵机制" class="headerlink" title="哨兵机制"></a>哨兵机制</h3><p>​    哨兵机制的出现，很显然就是去应对 redis 主从模式下出现的主库挂掉，导致服务中断或停止。在主从模式下，主库如果对写操作的服务中断，就会导致数据丢失，由此写操作就必须转给其他的从库，并且其他的从库还需要做数据同步</p>
<p>​    哨兵机制是一个运行在特殊模式下的 redis 进程，跟随主从库实例运行而运行，<strong>主要负责：监控、选择主库 以及 通知</strong></p>
<p>​    <strong>监控：</strong>哨兵进程运行后，会 <strong>周期性往所有主从库发送 ping 命令</strong>，对于响应超时的从库就会被哨兵认定为 “下线状态”；同理，主库也是如此，一旦主库没有响应，哨兵就需要切换主库</p>
<p>​    下线状态的判断，分为了两种：主观 和 客观下线。对于从库来说 ping 命令响应超时就可以主观判断为下线；但是对主库来说单纯使用 ping 去判断为主观下线会存在一定的问题</p>
<p>​    主库如果因为网络阻塞，或自身压力较大被单个哨兵误判为主观下线后，哨兵需要从新选主，以及后续的连接更改和从库同步，这一系列的过程的开销会很大。所以，对于主库而言，就不能使用单一哨兵去监控判断</p>
<p><img src="https://wei-foun.github.io/img/redis-%E4%B8%BB%E5%AE%A2%E8%A7%82%E5%88%A4%E6%96%AD.jpg" alt="img"></p>
<p>​    要避免对主库产生误判，哨兵的部署也可以使用集群方式，由多个哨兵对 redis 集群做监控判断，减少单个哨兵对主库判断的绝对决策权力，这样就可以使得主库被误判为下线的概率降低。多个哨兵按照 “少数服从多数” 的原则，即在 N 个哨兵实例下，建议是如果有 N/2+ 1 （这个数目并不是一定需要按照这个）个哨兵实例都认定主库处于下线状态，才能执行后续的重新选主，以及同步和重连，这样一来哨兵对主库的判断就变为客观判断了</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 配置</span><br><span class="line"># sentinel monitor &lt;master-name&gt; &lt;ip&gt; &lt;redis-port&gt; &lt;quorum&gt; </span><br><span class="line">sentinel monitor mymaster 192.168.13.1:6379 2</span><br><span class="line"></span><br><span class="line"># sentinel monitor 代表监控</span><br><span class="line"># mymaster 代表服务器的名称，可以自定义</span><br><span class="line"># 192.168.13.1 代表监控的主服务器，6379 代表端口</span><br><span class="line"># 2 代表只有两个或两个以上的哨兵认为主服务器不可用的时候，才会进行 failover (主从切换)操作</span><br></pre></td></tr></table></figure>
<p>​    启动时，需要使用 <code>redis-sentinel 哨兵的配置文件</code> 来运行哨兵</p>
<p>​    <strong>选主：</strong> <strong>哨兵选主大致分为两个部分 “筛选” 和 “打分”</strong></p>
<p>​    首先，肯定是要筛选掉下线的从库，其次还需要判断从库的网络连接状态，可以在配置文件中设置 down-after-milliseconds * 10 的配置项，表示实例与主库断开连接后尝试连接的最大超时时间，如果超出时间一直没有恢复主从连接，就认定为发生主从断连。10 表示就是发生断连的次数超过 10 次，那么可以认定当前实例的网络状态并不好，也就不适合作为新的主库，从而筛选掉</p>
<p>​    之后，就是 <strong>打分的环节，分为了三个阶段，依次是优先级、复制进度和从库自己的 ID</strong>。在任何一阶段中，得到最高分的从库就可以被作为新的主库，并退出后续的阶段，所以如果分数相同，就会进入下一阶段去打分</p>
<p>​    <strong>通知：</strong>当哨兵选出新的主库后，就需要将这个新主库发送给其他的从库，告知主库已经更换，那么从库就会通过执行 repliaof 来与新主库进行同步；除此之外，哨兵还需要通知连接的客户端，让他们与新主库进行连接</p>
<h3 id="发布与订阅"><a href="#发布与订阅" class="headerlink" title="发布与订阅"></a>发布与订阅</h3><p>​    <strong>配置哨兵集群下，各个哨兵的互相发现，利用就是 redis 的 pub/sub 机制</strong>。哨兵与主库建立连接后，就会获取到主库的 ip 和 端口，当主库开启了发布与订阅功能，各个哨兵实例就能通过主库知道其他哨兵的 ip 和 端口，这样一来哨兵集群就能实现消息传递，比如前面的主库是否下线的判断信息传递</p>
<p>​    发布订阅除了哨兵可以使用之外，自己编写的应用程序也能通过 redis 实现发布和订阅。那么为了区分开不同应用的消息，发布订阅模式就产生了频道，来进行区分。比如在主库上，所有的关联的哨兵都通过 <code>__sentinel__:hello</code> 频道交流，由此构建成哨兵集群</p>
<p>​    <strong>补充：</strong>哨兵集群中，<strong>当有哨兵实例认为主库处于主观下线后，会通过频道向其他哨兵发送 is-master-down-by-addr 的命令，其余哨兵会检测自己与主库的连接，返回 Y 或 N 表示自己与主句是否可连来做出投票</strong>。当最终赞成票数达到了配置 quorum 的设定值，那么就认定主库处于客观下线状态    </p>
<p><img src="https://wei-foun.github.io/img/redis-%E5%93%A8%E5%85%B5%E6%B2%9F%E9%80%9A.jpg" alt="img"></p>
<p>​    另外，哨兵集群完成了主库的下线判断，还需要选出一个哨兵做最后的主从切换，所以依然会通过发布订阅机制再去进行投票选出一个 leader。如果一个哨兵想成为 leader，它需要满足两个条件：1）拿到半数以上的投票  2）这个票数要大于等于 quorum 的值</p>
<p>​    当一个哨兵认为主库已经客观下线，并且自己想成为 leader，就会首先给自己投一票，并将发送命令给其余哨兵。其余哨兵如果同样判断主库是客观下线后，会是同样的操作。<strong>注意，每一个哨兵都只有一次投票机会，都是默认给自己投票，当有的哨兵没有判断主库客观下线后，会优先给第一个收到投票请求的哨兵投票，之后其余的哨兵全部都给反对票</strong></p>
<p>​    如果在一次选择 leader 中没有结果，哨兵集群会等待故障转移的 2 倍的时间，再次进行一轮 leader 的选举。注意，如果一个哨兵集群只有两个实例，一个哨兵要称为 leader 就需要得到 2 票，如果其中一个哨兵挂掉，那么就无法进行主从切换，所以一个哨兵集群最低保险是配置 3 个哨兵</p>
<p>​    前文说到，哨兵能够完成主从的切换，所以哨兵自然也需要和从库建立连接，它会发送 info 命令给主库，主库会将自己的从库列表发送哨兵，由此哨兵就能知道与主库连接的从库并与之建立连接</p>
<p>​    同时由于 pub/sub 的机制存在，使得客户端也能与哨兵进行交流，这样一来客户端就能通过频道知道主从之间的一些状态信息</p>
<p><img src="https://wei-foun.github.io/img/redis-pub-sub.jpg" alt="img"></p>
<p>​    那么哨兵完成主从切换后，客户端通过 switch_master 频道知道新的主库的 ip 和端口，从而实现与新主库的连接</p>
<h3 id="Redis-事务"><a href="#Redis-事务" class="headerlink" title="Redis 事务"></a>Redis 事务</h3><p>​    <strong>redis 中事务表现的是将多个命令组合进行一次性执行</strong></p>
<p>​    <strong>原子性（A）</strong>： redis 中 <strong>单独执行一个命令是具有原子性的</strong>，但是在事务中，<strong>多个命令执行并不就有原子性，因为多个命令执行没有回滚机制来保证全成功和全失败，但是在 redis 的客户端对于错误的命令会进行提示，来告知命令错误，此时去执行 exec ，那么事务就不会执行</strong></p>
<p>​    <strong>一致性（C）</strong>：<strong>redis 要保持一致性，需要通过命令来进行监控 key，如果 key 被其他事务修改则中断当前事务</strong></p>
<p>​    <strong>隔离性（I）</strong>：<strong>因为单线程的命令指令，所以 redis 本身就能够去实现</strong></p>
<p>​    <strong>持久性（D）</strong>：虽然 redis 执行 <strong>RDB 与 AOF 进行数据持久化，但是两种方式依然不能完全保证数据不会丢失的情况</strong></p>
<p>​    redis 事务执行有三个重要保证：</p>
<p>​    1）批量执行多个命令前，这个操作会先被放入队列缓存中</p>
<p>​    2）执行 EXEC 命令进入事务执行，在事务执行期间，任意命令如果执行失败，不会干扰其他命令执行</p>
<p>​    3）事务执行过程中，其他客户端提交的命令不会插入到事务执行命令的序列中</p>
<p>​    <strong>如果需要在 redis 中启动事务的方式，需要使用 <code>multi</code> 这个命令，之后的所有命令都会加入到事务的队列中，通过执行 <code>EXEC</code> 执行该事务</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">redis 127.0.0.1:6379&gt; MULTI</span><br><span class="line">OK</span><br><span class="line"></span><br><span class="line">redis 127.0.0.1:6379&gt; SET book-name &quot;Mastering C++ in 21 days&quot;</span><br><span class="line">QUEUED</span><br><span class="line"></span><br><span class="line">redis 127.0.0.1:6379&gt; GET book-name</span><br><span class="line">QUEUED</span><br><span class="line"></span><br><span class="line">redis 127.0.0.1:6379&gt; SADD tag &quot;C++&quot; &quot;Programming&quot; &quot;Mastering Series&quot;</span><br><span class="line">QUEUED</span><br><span class="line"></span><br><span class="line">redis 127.0.0.1:6379&gt; SMEMBERS tag</span><br><span class="line">QUEUED</span><br><span class="line"></span><br><span class="line">redis 127.0.0.1:6379&gt; EXEC</span><br><span class="line">1) OK</span><br><span class="line">2) &quot;Mastering C++ in 21 days&quot;</span><br><span class="line">3) (integer) 3</span><br><span class="line">4) 1) &quot;Mastering Series&quot;</span><br><span class="line">   2) &quot;C++&quot;</span><br><span class="line">   3) &quot;Programming&quot;</span><br></pre></td></tr></table></figure>
<p>​    <strong>如果要取消事务，放弃事务队列中的命令，可以执行 <code>DISCARD</code></strong></p>
<p>​    <strong>要实现一致性，需要通过 <code>WATCH key [key1 ...]</code>，会将指定的 key 进行监控</strong>，此时如果 客户端 1 使用 <code>MULTI</code> 开启事务，并使用到被监控的 key 进行修改操作，但没有执行该事务，客户端 2 此时同样对被监控的 key 进行了修改，这个时候 客户端 2 上的命令都是可以正常执行的。之后如果 客户端 1 使用 <code>EXEC</code> 开始执行事务则不会有返回，命令不会生效，并且被监控的 key 都会被取消监控</p>
<p>​    另外，在 python 中实现事务的话，使用 pipline 方法中 transaction 参数为 True 表示开启事务，通过 pipline 对象的 execute 方法来执行事务</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> redis</span><br><span class="line"> </span><br><span class="line">pool = redis.ConnectionPool(host=<span class="string">&#x27;127.0.0.1&#x27;</span>, port=<span class="number">6379</span>)</span><br><span class="line"> </span><br><span class="line">r = redis.Redis(connection_pool=pool)</span><br><span class="line"></span><br><span class="line">pipe = r.pipeline(transaction=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">pipe.multi()</span><br><span class="line"></span><br><span class="line">pipe.<span class="built_in">set</span>(<span class="string">&#x27;name&#x27;</span>, <span class="string">&#x27;alex&#x27;</span>)</span><br><span class="line">pipe.<span class="built_in">set</span>(<span class="string">&#x27;role&#x27;</span>, <span class="string">&#x27;sb&#x27;</span>)</span><br><span class="line"> </span><br><span class="line">pipe.execute()</span><br></pre></td></tr></table></figure>
<h3 id="Redis-分布式锁"><a href="#Redis-分布式锁" class="headerlink" title="Redis 分布式锁"></a>Redis 分布式锁</h3><h4 id="单-redis-节点的分布式锁"><a href="#单-redis-节点的分布式锁" class="headerlink" title="单 redis 节点的分布式锁"></a>单 redis 节点的分布式锁</h4><p>​    在分布式系统中，锁是保存在一个共享存储系统上的，这就允许了可以被多个客户端去进行访问和获取，而 redis 本身就允许多个客户端进行访问，天生就可以作为一个共享存储系统，所以单个 redis 节点就能提供分布式锁的功能</p>
<p>​    分布式锁和一般单机程序逻辑上锁类似，使用 redis 来实现分布式锁，可以通过一个键值对来进行设置 <code>setnx key value</code>，可以将 key 的值设置为 0，0 表示没有客户端持有锁，当有客户端要上锁，就将值设为 1</p>
<p><img src="https://static001.geekbang.org/resource/image/1d/45/1d18742c1e5fc88835ec27f1becfc145.jpg" alt="img"> </p>
<p><img src="https://static001.geekbang.org/resource/image/c7/82/c7c413b47d42f06f08fce92404f31e82.jpg" alt="img"> </p>
<p>​    对于加锁操作，客户端通过 <code>setnx</code> 去设置，通过 <code>del</code> 删除 key 来释放锁。虽然 <code>del</code> 会删除 key，但是对于加锁的 <code>setnx</code> 来说，会先去判断 key 是否存在，不存在就创建。这样也很好解决了一个判断问题，因为原本设想的是 0 表示释放锁，1 表示加锁。但是当一个客户端创建并最后释放，锁的值被改为 0，其他的客户端要获得锁，要还需要查询一次进行一步判断是否 key 存在，不存在才能去申请锁</p>
<p>​    释放锁通过 <code>del</code> 操作，对于其他客户端而言，加锁的操作就不用多一步值的判断问题，<code>setnx</code> 会在锁的 key 存在情况下，不会执行操作来修改，这样即使客户端没有释放，其他客户端去执行加锁操作，通过判断到 key 的存在，而无法得到锁</p>
<p>​    但是仅仅通过 <code>setnx</code> 和 <code>del</code> 来做加锁和释放锁的操作依然有问题，如果一个客户端在获得锁后一直没有释放锁，就会导致其他客户端无法获取锁，所以在设置创建 key 的时候，同时加上 <strong>过期时间</strong>，比如 <code>set</code> 命令中的 <code>ex</code> 参数设置过期时间，这样即使一个客户端在获取锁后，可能因为异常导致一直占用着锁，但是一旦锁到期就被自动被释放，让其他的客户端去请求加锁</p>
<p>​    不过给 key 加上了过期时间，依然还是有问题存在，因为释放锁通过 <code>DEL</code> 来执行，如果 客户端 1 设了 key 获取到锁，但是却被 客户端 2 执行了 <code>DEL</code> 删除该 key，那么就会导致 客户端 1 的锁被误释放，其他客户端就会去申请创建 key 来加锁，一样会给业务处理带来问题</p>
<p>​    所以为了防止锁被误删，就需要改变 value，<strong>让 value 能具有代表加锁客户端的唯一标识作用，比如使用 uuid 等</strong>，这样每次释放锁就需要判断锁变量的值与唯一标识是否一致才能执行 <code>DEL</code> 将锁释放</p>
<h4 id="多-redis-节点的分布式锁"><a href="#多-redis-节点的分布式锁" class="headerlink" title="多 redis 节点的分布式锁"></a>多 redis 节点的分布式锁</h4><p>​    单节点虽然可以实现分布式锁，一旦 redis 出现单点故障异常宕机，那么整个分布式锁就无法使用。所以要想使得整个服务系统更加健壮，就不得不增加 redis 实例，可以利用 redis 主从模式来设置分布式锁，虽然相对而言比单点有了保障，但依旧不能彻底解决问题，master 如果出现异常，需要进行主从切换，这个时间内 redis 不能接收数据就会丢失这一时间段的所有数据</p>
<p>​    所以要实现高可靠的分布式锁，就需要使用更多的 redis 实例，redis 为了解决前面单点和主从模式下的问题，提供了一个 <strong>RedLock 的分布式锁算法</strong></p>
<p>​    <strong>RedLock 算法基本思路是，当客户端需要申请创建锁时，需要依次向所有的 redis 实例上去创建锁，如果能够在超过半数的节点上实现加锁操作则意味着客户端成功获取分布式锁，否则加锁就是失败的</strong></p>
<p>​    这样即使单个节点故障，设置的锁变量 key 在其他 redis 节点上也都有保存，客户端依然可以用相同的逻辑来获取</p>
<h5 id="RedLock"><a href="#RedLock" class="headerlink" title="RedLock"></a>RedLock</h5><p>​    对于 Redlock 算法的执行大致分为 3 个步骤：</p>
<p>​    1）获取当前的时间戳，单位是毫秒级</p>
<p>​    2）客户端依次向 N 个 redis 实例进行创建锁，同时给这个加锁过程设置超时时间，这样如果一个 redis 实例一直没有成功创建，客户端会跳过继续往后的 redis 实例进行创建，对于超时时间的设置肯定需要远小于锁的过期时间，这个超时时间一般可以设置为几十毫秒</p>
<p>​    3）只要客户端完成向所有的 redis 实例实现加锁操作后，客户端会立即计算整个加锁过程的总耗时</p>
<p>​    最后，<strong>对于是否加锁成功，其实有两个条件判断：</strong></p>
<p>​    1）超过 N/2+1 的 redis 实例上都成功加上了锁</p>
<p>​    2）客户端完成操作后的统计的总耗时没有超过锁设置的过期时间</p>
<p>​    <strong>同时满足两个后，还需要重新对锁的有效时间进行计算，通过锁原本的有效时间 - 客户端统计的总耗时 = 新的有效时间，要是无法同时满足两个条件，客户端会向所有实例去释放锁，删除已创建的 key</strong></p>
<p>​    如果锁的新的有效时间不足以完成数据的操作，则会将锁进行释放，防止出现数据没处理完，锁就因为到达过期时间而被自动释放</p>
<p>​    当一个客户端得到锁后，其他的客户端会不断轮询来尝试获取锁</p>
<h4 id="其他分布式锁方式"><a href="#其他分布式锁方式" class="headerlink" title="其他分布式锁方式"></a>其他分布式锁方式</h4><p>​    比如 Redisson ，Zookeeper 等</p>
<h3 id="缓存方式"><a href="#缓存方式" class="headerlink" title="缓存方式"></a>缓存方式</h3><p>​    缓存已经是现在任何应用系统都不可少的模块，也是高并发高性能架构中的一个重要的组件</p>
<p>​    使用缓存一是能够缓解对数据库的压力，而是能够提升系统的整体处理性能，比如热点数据，或是对实时性要求不高的数据放在缓存中，请求可以直接向缓存中获取，就不用对数据库进行查询操作</p>
<p>​    一般来说，<strong>缓存有三种模式：Cache Aside，Read / Write Through，Write Behind Caching</strong></p>
<h4 id="Cache-Aside"><a href="#Cache-Aside" class="headerlink" title="Cache Aside"></a>Cache Aside</h4><p>​    表示 <strong>同时更新缓存和数据库</strong>，这是最常用的一种缓存方式，对于数据的查询操作，如果能从缓存中得到即命中，就直接返回；如果没有则表示获取操作失效，即需要查询数据库来获取，同时将得到的数据放到缓存中</p>
<p>​    但是对于更新操作，就需要避免数据一致性的问题，比如是先更新缓存还是先更新数据库</p>
<p>​    1）先更新数据库，再更新缓存</p>
<p>​    这种方式最容易遇到一个问题，就是在并发情况下，更新操作没有全部完成，请求就先从缓存中读到了数据，但是这个数据其实是脏数据，这样就出现数据库和缓存的数据不一致问题</p>
<p>​    2）先删除缓存，再更新数据库</p>
<p>​    和上面的方式一样会遇到不一致的问题，虽然缓存被删除，但是如果有另一个请求获取数据，对缓存来说就是失效的，请求就会从数据库上获取，如果数据库的更新操作还没执行，那么就会从数据库上读到旧数据</p>
<p>​    3）<strong>先更新数据库，再删除缓存</strong></p>
<p>​    相比前两种，先在数据库更新，然后将缓存删除这样的方式要更好，但是依然会有脏数据的问题，并发情况下，如果读操作没有命中缓存，读到了数据库中的旧数据，同时更新操作对数据库更新了，也将缓存删除了，而之前的读操作则又会将旧数据放到缓存中，那后续的读就是脏数据了</p>
<p>​    但是这样的情况概率很低，需要缓存失效同时有读写操作，一般情况读操作远远多于写的操作</p>
<h4 id="Read-Write-Through"><a href="#Read-Write-Through" class="headerlink" title="Read / Write Through"></a>Read / Write Through</h4><p>​    表示 <strong>先更新缓存，在通过缓存负责将数据 同步 到数据库上</strong></p>
<h4 id="Write-Behind-Caching"><a href="#Write-Behind-Caching" class="headerlink" title="Write Behind Caching"></a>Write Behind Caching</h4><p>​    表示 <strong>先更新缓存，在通过定期的方式 异步 更新数据到数据库上</strong></p>
<h3 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a>缓存穿透</h3><p>​    指的是：<strong>缓存与数据库中没有的数据被大量不断的请求，使得查询操作不能命中缓存，导致数据库的压力过大</strong></p>
<p>​    比如一些简单的爬虫根据标签或路由的 id 进行遍历发送请求，但是对于一些数据可能并不是按照 id 自增的方式创建的</p>
<p>​    <strong>解决方法：</strong>可以对查询不到的结果定义一个 None 返回，并将其放入到缓存，这样之后的请求就会回到缓存上获取</p>
<h3 id="缓存击穿"><a href="#缓存击穿" class="headerlink" title="缓存击穿"></a>缓存击穿</h3><p>​    指的是：<strong>缓存上的数据出现了批量的过期，导致原本在缓存上获取的请求突然全部打到数据库上，使得数据库压力瞬间增大</strong></p>
<p>​    击穿的问题是因为缓存上大量的 key 是相似时间创建的，并且所设置的过期时间也是一样的，所以会出现在某一时刻出现大批量的失效</p>
<p>​    <strong>解决方法：</strong>如果是热点的数据，且更新非常低，可将这些数据不设置过期时间，这样不会导致失效而打到数据库上，或是通过编写脚本异步后台定期对缓存上快过期的 key 进行一个刷新；另外，也可以通过加锁的方式，当出现数据过期，让有锁的线程单独从数据库上拉取数据到缓存，其他的线程等待缓存中有数据了，再去缓存上取</p>
<h3 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a>缓存雪崩</h3><p>​    指的是：<strong>缓存突然不可用，或是缓存上的不同类型的数据都出现大批量的失效，导致请求打到数据库上</strong>，雪崩也很容易理解，相比击穿来说，失效的数据要远大于击穿中失效的数据</p>
<p>​    缓存节点可能因为各种原因出现异常挂机，那么此时这个缓存上的所有数据都无法被查询命中，大量的并发请求就甚至可能把数据库也打挂掉。另外，因为 redis 存储支持丰富的数据类型可以存放不同功能所需要的数据，当过期时间一致时就容易出现和击穿一样的问题</p>
<p>​    <strong>解决方法：</strong>对于不同类型或级别的数据，设置不同的超时时间，或者创建 key 的时候使用随机的超时时间，避免同一时刻大量的失效；对于缓存不可用，就需要提升系统整个健壮性，添加监控和报警，使用主从节点</p>
<p>​    </p>
<p>​    </p>
<p>​        </p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="http://example.com">Legacy</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://example.com/3714377604/">http://example.com/3714377604/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://example.com" target="_blank"></a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/redis/">redis</a></div><div class="post_share"><div class="social-share" data-image="https://wei-foun.github.io/img/cover30.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/1674812330/"><img class="prev-cover" src="https://wei-foun.github.io/img/cover31.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Mysql-整理-三</div></div></a></div><div class="next-post pull-right"><a href="/2237286045/"><img class="next-cover" src="https://wei-foun.github.io/img/cover29.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Elasticsearch 整理</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/645115729/" title="Redis 基本命令和配置"><img class="cover" src="https://wei-foun.github.io/img/cover27.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-11-29</div><div class="title">Redis 基本命令和配置</div></div></a></div><div><a href="/311488900/" title="redis-消息队列"><img class="cover" src="https://wei-foun.github.io/img/cover40.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-11-21</div><div class="title">redis-消息队列</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/avatar.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Legacy</div><div class="author-info__description">冒险的生涯在召唤！</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">48</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">30</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">45</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">Live a life you will remember</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#Redis-%E6%A6%82%E8%A7%88"><span class="toc-number">1.</span> <span class="toc-text">Redis 概览</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Redis-%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E5%8F%8A%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="toc-number">2.</span> <span class="toc-text">Redis 数据类型及使用场景</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BA%94%E7%A7%8D%E7%B1%BB%E5%9E%8B%E7%9A%84%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0"><span class="toc-number">2.1.</span> <span class="toc-text">五种类型的底层实现</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%A8%E5%B1%80%E5%93%88%E5%B8%8C%E8%A1%A8"><span class="toc-number">2.2.</span> <span class="toc-text">全局哈希表</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E7%9A%84%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4"><span class="toc-number">2.3.</span> <span class="toc-text">数据类型的常用命令</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%A1%A5%E5%85%85%EF%BC%9ARedisObject"><span class="toc-number">2.4.</span> <span class="toc-text">补充：RedisObject</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8C%81%E4%B9%85%E5%8C%96"><span class="toc-number">3.</span> <span class="toc-text">持久化</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#RDB"><span class="toc-number">3.1.</span> <span class="toc-text">RDB</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#AOF"><span class="toc-number">3.2.</span> <span class="toc-text">AOF</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%A4%E8%80%85%E7%9A%84%E4%BC%98%E7%BC%BA%E7%82%B9"><span class="toc-number">3.3.</span> <span class="toc-text">两者的优缺点</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B7%B7%E5%90%88%E6%8C%81%E4%B9%85%E5%8C%96"><span class="toc-number">3.4.</span> <span class="toc-text">混合持久化</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Redis-%E4%B8%BB%E4%BB%8E%E6%A8%A1%E5%BC%8F"><span class="toc-number">4.</span> <span class="toc-text">Redis 主从模式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%93%A8%E5%85%B5%E6%9C%BA%E5%88%B6"><span class="toc-number">5.</span> <span class="toc-text">哨兵机制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8F%91%E5%B8%83%E4%B8%8E%E8%AE%A2%E9%98%85"><span class="toc-number">6.</span> <span class="toc-text">发布与订阅</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Redis-%E4%BA%8B%E5%8A%A1"><span class="toc-number">7.</span> <span class="toc-text">Redis 事务</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Redis-%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81"><span class="toc-number">8.</span> <span class="toc-text">Redis 分布式锁</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8D%95-redis-%E8%8A%82%E7%82%B9%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81"><span class="toc-number">8.1.</span> <span class="toc-text">单 redis 节点的分布式锁</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A4%9A-redis-%E8%8A%82%E7%82%B9%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81"><span class="toc-number">8.2.</span> <span class="toc-text">多 redis 节点的分布式锁</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#RedLock"><span class="toc-number">8.2.1.</span> <span class="toc-text">RedLock</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%B6%E4%BB%96%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E6%96%B9%E5%BC%8F"><span class="toc-number">8.3.</span> <span class="toc-text">其他分布式锁方式</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BC%93%E5%AD%98%E6%96%B9%E5%BC%8F"><span class="toc-number">9.</span> <span class="toc-text">缓存方式</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Cache-Aside"><span class="toc-number">9.1.</span> <span class="toc-text">Cache Aside</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Read-Write-Through"><span class="toc-number">9.2.</span> <span class="toc-text">Read &#x2F; Write Through</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Write-Behind-Caching"><span class="toc-number">9.3.</span> <span class="toc-text">Write Behind Caching</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F"><span class="toc-number">10.</span> <span class="toc-text">缓存穿透</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BC%93%E5%AD%98%E5%87%BB%E7%A9%BF"><span class="toc-number">11.</span> <span class="toc-text">缓存击穿</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9"><span class="toc-number">12.</span> <span class="toc-text">缓存雪崩</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2133446919/" title="Linux再学习"><img src="https://wei-foun.github.io/img/cover46.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Linux再学习"/></a><div class="content"><a class="title" href="/2133446919/" title="Linux再学习">Linux再学习</a><time datetime="2025-07-12T06:58:04.000Z" title="发表于 2025-07-12 14:58:04">2025-07-12</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/4075015966/" title="GO 基础"><img src="https://wei-foun.github.io/img/cover45.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="GO 基础"/></a><div class="content"><a class="title" href="/4075015966/" title="GO 基础">GO 基础</a><time datetime="2025-07-04T16:26:58.000Z" title="发表于 2025-07-05 00:26:58">2025-07-05</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/4209932858/" title="容器网络"><img src="https://wei-foun.github.io/img/cover44.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="容器网络"/></a><div class="content"><a class="title" href="/4209932858/" title="容器网络">容器网络</a><time datetime="2023-07-04T16:26:58.000Z" title="发表于 2023-07-05 00:26:58">2023-07-05</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/4253636491/" title="kubernetes-搭建"><img src="https://wei-foun.github.io/img/cover43.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="kubernetes-搭建"/></a><div class="content"><a class="title" href="/4253636491/" title="kubernetes-搭建">kubernetes-搭建</a><time datetime="2023-03-19T10:39:02.000Z" title="发表于 2023-03-19 18:39:02">2023-03-19</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/undefined/" title="wsl docker 卸载"><img src="https://wei-foun.github.io/img/cover42.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="wsl docker 卸载"/></a><div class="content"><a class="title" href="/undefined/" title="wsl docker 卸载">wsl docker 卸载</a><time datetime="2023-03-05T08:50:50.000Z" title="发表于 2023-03-05 16:50:50">2023-03-05</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url('https://wei-foun.github.io/img/cover30.jpg')"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2025 By Legacy</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="/js/search/local-search.js"></script><script>var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',preloader.endLoading())</script><div class="js-pjax"><script>function loadValine () {
  function initValine () {
    const valine = new Valine(Object.assign({
      el: '#vcomment',
      appId: 'MHzSjOElX9Cf5IJAfoNr4COL-gzGzoHsz',
      appKey: 'K3d5HK6zRMD2BINwstEANt7H',
      avatar: 'monsterid',
      serverURLs: '',
      emojiMaps: {"tv_doge":"6ea59c827c414b4a2955fe79e0f6fd3dcd515e24.png","tv_親親":"a8111ad55953ef5e3be3327ef94eb4a39d535d06.png","tv_偷笑":"bb690d4107620f1c15cff29509db529a73aee261.png","tv_再見":"180129b8ea851044ce71caf55cc8ce44bd4a4fc8.png","tv_冷漠":"b9cbc755c2b3ee43be07ca13de84e5b699a3f101.png","tv_發怒":"34ba3cd204d5b05fec70ce08fa9fa0dd612409ff.png","tv_發財":"34db290afd2963723c6eb3c4560667db7253a21a.png","tv_可愛":"9e55fd9b500ac4b96613539f1ce2f9499e314ed9.png","tv_吐血":"09dd16a7aa59b77baa1155d47484409624470c77.png","tv_呆":"fe1179ebaa191569b0d31cecafe7a2cd1c951c9d.png","tv_嘔吐":"9f996894a39e282ccf5e66856af49483f81870f3.png","tv_困":"241ee304e44c0af029adceb294399391e4737ef2.png","tv_壞笑":"1f0b87f731a671079842116e0991c91c2c88645a.png","tv_大佬":"093c1e2c490161aca397afc45573c877cdead616.png","tv_大哭":"23269aeb35f99daee28dda129676f6e9ea87934f.png","tv_委屈":"d04dba7b5465779e9755d2ab6f0a897b9b33bb77.png","tv_害羞":"a37683fb5642fa3ddfc7f4e5525fd13e42a2bdb1.png","tv_尷尬":"7cfa62dafc59798a3d3fb262d421eeeff166cfa4.png","tv_微笑":"70dc5c7b56f93eb61bddba11e28fb1d18fddcd4c.png","tv_思考":"90cf159733e558137ed20aa04d09964436f618a1.png","tv_驚嚇":"0d15c7e2ee58e935adc6a7193ee042388adc22af.png"},
      path: window.location.pathname,
      visitor: true
    }, null))
  }

  if (typeof Valine === 'function') initValine() 
  else getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js').then(initValine)
}

if ('Valine' === 'Valine' || !true) {
  if (true) btf.loadComment(document.getElementById('vcomment'),loadValine)
  else setTimeout(loadValine, 0)
} else {
  function loadOtherComment () {
    loadValine()
  }
}</script></div><script defer="defer" id="ribbon" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-ribbon.min.js" size="150" alpha="0.6" zIndex="-1" mobile="false" data-click="false"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>